{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizer import porter_stem_tokenizer\n",
    "from tokenizer import snowball_stem_tokenizer\n",
    "from tokenizer import lancaster_stem_tokenizer\n",
    "from tokenizer import wordnet_lemma_tokenizer\n",
    "from tokenizer import wordnet_lemma_pos_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technology</td>\n",
       "      <td>21st-Century Sports: How Digital Technology Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Asian quake hits European shares Shares in Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technology</td>\n",
       "      <td>BT offers free net phone calls BT is offering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Barclays shares up on merger talk Shares in UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sport</td>\n",
       "      <td>Barkley fit for match in Ireland England centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>sport</td>\n",
       "      <td>Woodward eyes Brennan for Lions Toulouse's for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>business</td>\n",
       "      <td>WorldCom trial starts in New York The trial of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos accused of lying to court Russian oil fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos drops banks from court bid Russian oil c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>sport</td>\n",
       "      <td>Zambia confident and cautious Zambia's technic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                            content\n",
       "0     technology  21st-Century Sports: How Digital Technology Is...\n",
       "1       business  Asian quake hits European shares Shares in Eur...\n",
       "2     technology  BT offers free net phone calls BT is offering ...\n",
       "3       business  Barclays shares up on merger talk Shares in UK...\n",
       "4          sport  Barkley fit for match in Ireland England centr...\n",
       "...          ...                                                ...\n",
       "1403       sport  Woodward eyes Brennan for Lions Toulouse's for...\n",
       "1404    business  WorldCom trial starts in New York The trial of...\n",
       "1405    business  Yukos accused of lying to court Russian oil fi...\n",
       "1406    business  Yukos drops banks from court bid Russian oil c...\n",
       "1407       sport  Zambia confident and cautious Zambia's technic...\n",
       "\n",
       "[1408 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "with open(f'{ROOT_PATH}/data/datastore/article_titles_plus_contents_all.txt', mode='r', encoding='utf-8') as file:\n",
    "  raw_contents = file.read().splitlines()\n",
    "\n",
    "with open(f'{ROOT_PATH}/data/target/article_categories_all.txt', mode='r', encoding='utf-8') as file:\n",
    "  target = file.read().splitlines()\n",
    "\n",
    "raw_df = pd.DataFrame({\n",
    "    'category': target,\n",
    "    'content': raw_contents\n",
    "})\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tokenizing(tokenizer, X):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer, min_df=.01)\n",
    "    tf_idf = vectorizer.fit_transform(X)\n",
    "    return tf_idf\n",
    "\n",
    "def model_testing(tokenizers, models, X_train, Y_train):\n",
    "    cv_result = {\n",
    "        \"model_name\": [],\n",
    "        \"tokenizer_name\": [],\n",
    "        \"score (default_params)\": []\n",
    "    }\n",
    "    for tokenizer in tokenizers:\n",
    "        tokenized = tokenizing(tokenizer, X_train)\n",
    "        for model in models:\n",
    "            cv_score = cross_val_score(model, tokenized, Y_train, cv=5, )\n",
    "            cv_result[\"model_name\"].append(type(model).__name__)\n",
    "            cv_result[\"tokenizer_name\"].append(tokenizer.__name__)\n",
    "            cv_result[\"score (default_params)\"].append(cv_score.mean())\n",
    "    result_df = pd.DataFrame(cv_result).sort_values(by=['score (default_params)'], ascending=False)\n",
    "    return result_df\n",
    "\n",
    "def parameter_tuning(tokenizers, models, params, X_train, Y_train):\n",
    "    tuning_result = {\n",
    "        \"model_name\": [],\n",
    "        \"tokenizer_name\": [],\n",
    "        \"best_parameter\": [],\n",
    "        \"best_score\": []\n",
    "    }\n",
    "    for tokenizer in tokenizers:\n",
    "        tokenized = tokenizing(tokenizer, X_train)\n",
    "        for model, param in zip(models, params.values()):\n",
    "            clf = GridSearchCV(model, param, cv=5, n_jobs=-1, verbose=1)\n",
    "            result = clf.fit(tokenized, Y_train)\n",
    "            tuning_result['model_name'].append(type(model).__name__)\n",
    "            tuning_result['tokenizer_name'].append(tokenizer.__name__)\n",
    "            tuning_result['best_score'].append(result.best_score_)\n",
    "            tuning_result['best_parameter'].append(result.best_params_)\n",
    "    tuning_result = pd.DataFrame(tuning_result).sort_values(by=['best_score'], ascending=False)\n",
    "    return tuning_result\n",
    "\n",
    "def compare_result(untune_result, tuned_result):\n",
    "    compare_result = pd.merge(untune_result,\n",
    "                                tuned_result,\n",
    "                                how='inner',\n",
    "                                on=['model_name', 'tokenizer_name']\n",
    "                                )[['model_name', 'tokenizer_name', 'score (default_params)', 'best_score', 'best_parameter']]\n",
    "    compare_result['variance'] = compare_result['best_score'] - compare_result['score (default_params)']\n",
    "    return compare_result.sort_values(by=['best_score'], ascending=False, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "\n",
    "tokenizers = [porter_stem_tokenizer, snowball_stem_tokenizer,\n",
    "              lancaster_stem_tokenizer, wordnet_lemma_tokenizer, \n",
    "              wordnet_lemma_pos_tokenizer]\n",
    "\n",
    "# Define model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [KNeighborsClassifier(), LogisticRegression()]\n",
    "\n",
    "# Define parameter\n",
    "params ={\n",
    "    \"knn_params\":{\n",
    "        'n_neighbors' : list(range(1, 16))\n",
    "    },\n",
    "    # \"r2f_params\":{\n",
    "    #     'max_depth': list(range(50, 60, 2)),\n",
    "    #     'min_samples_split': list(range(2, 10, 2))\n",
    "    # },\n",
    "    \"logis_params\":{\n",
    "        \"solver\" : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        \"C\": list(np.arange(0.1, 1.1, 0.1))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_df['content'].values\n",
    "Y = raw_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,Y, random_state=50, test_size=.33, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tokenizer_name</th>\n",
       "      <th>score (default_params)</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_parameter</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>{'C': 0.9, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>{'C': 0.8, 'solver': 'saga'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>{'C': 0.8, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>{'C': 0.7000000000000001, 'solver': 'saga'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.980907</td>\n",
       "      <td>0.980907</td>\n",
       "      <td>{'C': 0.6, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.955454</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.013796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.959704</td>\n",
       "      <td>0.968192</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.959693</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.008494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.957582</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.010605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.010588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name               tokenizer_name  score (default_params)  \\\n",
       "0    LogisticRegression  wordnet_lemma_pos_tokenizer                0.984088   \n",
       "1    LogisticRegression        porter_stem_tokenizer                0.983029   \n",
       "2    LogisticRegression      snowball_stem_tokenizer                0.983029   \n",
       "3    LogisticRegression     lancaster_stem_tokenizer                0.980913   \n",
       "4    LogisticRegression      wordnet_lemma_tokenizer                0.980907   \n",
       "5  KNeighborsClassifier     lancaster_stem_tokenizer                0.955454   \n",
       "6  KNeighborsClassifier      snowball_stem_tokenizer                0.959704   \n",
       "7  KNeighborsClassifier        porter_stem_tokenizer                0.959693   \n",
       "8  KNeighborsClassifier  wordnet_lemma_pos_tokenizer                0.957582   \n",
       "9  KNeighborsClassifier      wordnet_lemma_tokenizer                0.956535   \n",
       "\n",
       "   best_score                               best_parameter  variance  \n",
       "0    0.984088            {'C': 0.9, 'solver': 'newton-cg'}  0.000000  \n",
       "1    0.983029                 {'C': 0.8, 'solver': 'saga'}  0.000000  \n",
       "2    0.983029            {'C': 0.8, 'solver': 'newton-cg'}  0.000000  \n",
       "3    0.980913  {'C': 0.7000000000000001, 'solver': 'saga'}  0.000000  \n",
       "4    0.980907            {'C': 0.6, 'solver': 'newton-cg'}  0.000000  \n",
       "5    0.969250                           {'n_neighbors': 7}  0.013796  \n",
       "6    0.968192                          {'n_neighbors': 13}  0.008488  \n",
       "7    0.968186                          {'n_neighbors': 13}  0.008494  \n",
       "8    0.968186                          {'n_neighbors': 15}  0.010605  \n",
       "9    0.967123                          {'n_neighbors': 11}  0.010588  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run pipline\n",
    "test_result = model_testing(tokenizers, models, X_train, y_train)\n",
    "tuned_result = parameter_tuning(tokenizers, models, params, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tokenizer_name</th>\n",
       "      <th>score (default_params)</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_parameter</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>{'C': 0.9, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>{'C': 0.8, 'solver': 'saga'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>{'C': 0.8, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>{'C': 0.7000000000000001, 'solver': 'saga'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.980907</td>\n",
       "      <td>0.980907</td>\n",
       "      <td>{'C': 0.6, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.955454</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.013796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.959704</td>\n",
       "      <td>0.968192</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.959693</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.008494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.957582</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.010605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.010588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name               tokenizer_name  score (default_params)  \\\n",
       "0    LogisticRegression  wordnet_lemma_pos_tokenizer                0.984088   \n",
       "1    LogisticRegression        porter_stem_tokenizer                0.983029   \n",
       "2    LogisticRegression      snowball_stem_tokenizer                0.983029   \n",
       "3    LogisticRegression     lancaster_stem_tokenizer                0.980913   \n",
       "4    LogisticRegression      wordnet_lemma_tokenizer                0.980907   \n",
       "5  KNeighborsClassifier     lancaster_stem_tokenizer                0.955454   \n",
       "6  KNeighborsClassifier      snowball_stem_tokenizer                0.959704   \n",
       "7  KNeighborsClassifier        porter_stem_tokenizer                0.959693   \n",
       "8  KNeighborsClassifier  wordnet_lemma_pos_tokenizer                0.957582   \n",
       "9  KNeighborsClassifier      wordnet_lemma_tokenizer                0.956535   \n",
       "\n",
       "   best_score                               best_parameter  variance  \n",
       "0    0.984088            {'C': 0.9, 'solver': 'newton-cg'}  0.000000  \n",
       "1    0.983029                 {'C': 0.8, 'solver': 'saga'}  0.000000  \n",
       "2    0.983029            {'C': 0.8, 'solver': 'newton-cg'}  0.000000  \n",
       "3    0.980913  {'C': 0.7000000000000001, 'solver': 'saga'}  0.000000  \n",
       "4    0.980907            {'C': 0.6, 'solver': 'newton-cg'}  0.000000  \n",
       "5    0.969250                           {'n_neighbors': 7}  0.013796  \n",
       "6    0.968192                          {'n_neighbors': 13}  0.008488  \n",
       "7    0.968186                          {'n_neighbors': 13}  0.008494  \n",
       "8    0.968186                          {'n_neighbors': 15}  0.010605  \n",
       "9    0.967123                          {'n_neighbors': 11}  0.010588  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compare_result(test_result, tuned_result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def apply_best_method(best_model, best_tokenizer, best_params, X, Y):\n",
    "    X = tokenizing(best_tokenizer, X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,Y, random_state=50, test_size=.33, stratify=Y)\n",
    "    model = best_model.set_params(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    result = classification_report(y_test, pred)\n",
    "    print(accuracy_score(y_test, pred))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_model(model_name):\n",
    "    for model in models:\n",
    "        if model_name == type(model).__name__:\n",
    "            return model\n",
    "\n",
    "def map_tokenizer(tokenizer_name):\n",
    "    for tokenizer in tokenizers:\n",
    "        if tokenizer_name == tokenizer.__name__:\n",
    "            return tokenizer\n",
    "\n",
    "best_model = map_model(result.loc[0, 'model_name'])\n",
    "best_tokenizer = map_tokenizer(result.loc[0, 'tokenizer_name'])\n",
    "best_params = result.loc[0, 'best_parameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9741935483870968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.97      0.97      0.97       162\n",
      "       sport       0.99      0.99      0.99       174\n",
      "  technology       0.96      0.96      0.96       129\n",
      "\n",
      "    accuracy                           0.97       465\n",
      "   macro avg       0.97      0.97      0.97       465\n",
      "weighted avg       0.97      0.97      0.97       465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_best_method(best_model, best_tokenizer, best_params, X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d853cb24e8f7628e3ba29dc09518236c084a73039b3bc92092f3293b2fe13772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
