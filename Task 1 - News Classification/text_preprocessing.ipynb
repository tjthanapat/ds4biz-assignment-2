{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tjthanapat\\\\Documents\\\\GitHub\\\\ds4biz-assignment-2\\\\Task 1 - News Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "ROOT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{ROOT_PATH}/data/datastore/article_titles_plus_contents_all.txt', mode='r', encoding='utf-8') as file:\n",
    "   docs = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21st-Century Sports: How Digital Technology Is Changing the Face Of The Sporting Industry The sporting industry has come a long way since the ‘60s. It has carved out for itself a niche with its roots so deep that I cannot fathom the sports industry showing any sign of decline any time soon - or later. The reason can be found in this seemingly subtle difference - other industries have customers; the sporting industry has fans. Vivek Ranadivé, leader of the ownership group of the NBA’s Sacramento Kings, explained it beautifully, “Fans will paint their face purple, fans will evangelize. ... Every other CEO in every business is dying to be in our position — they’re dying to have fans.“ While fan passion alone could almost certainly keep the industry going, leagues and sporting franchises have decided not to rest on their laurels. The last few years have seen the steady introduction of technology into the world of sports - amplifying fans’ appreciation of games, enhancing athletes’ public profiles and informing their training methods, even influencing how contests are waged. Also, digital technology in particular has helped to create an alternative source of revenue, besides the games themselves - corporate sponsorship. They achieved this by capitalizing on the ardor of their customer base - sorry, fan base.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st', 'century', 'sports', 'how', 'digital', 'technology', 'is', 'changing', 'the', 'face', 'of', 'the', 'sporting', 'industry', 'the', 'sporting', 'industry', 'has', 'come', 'long', 'way', 'since', 'the', '60s', 'it', 'has', 'carved', 'out', 'for', 'itself', 'niche', 'with', 'its', 'roots', 'so', 'deep', 'that', 'cannot', 'fathom', 'the', 'sports', 'industry', 'showing', 'any', 'sign', 'of', 'decline', 'any', 'time', 'soon', 'or', 'later', 'the', 'reason', 'can', 'be', 'found', 'in', 'this', 'seemingly', 'subtle', 'difference', 'other', 'industries', 'have', 'customers', 'the', 'sporting', 'industry', 'has', 'fans', 'vivek', 'ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'nba', 'sacramento', 'kings', 'explained', 'it', 'beautifully', 'fans', 'will', 'paint', 'their', 'face', 'purple', 'fans', 'will', 'evangelize', 'every', 'other', 'ceo', 'in', 'every', 'business', 'is', 'dying', 'to', 'be', 'in', 'our', 'position', 'they', 're', 'dying', 'to', 'have', 'fans', 'while', 'fan', 'passion', 'alone', 'could', 'almost', 'certainly', 'keep', 'the', 'industry', 'going', 'leagues', 'and', 'sporting', 'franchises', 'have', 'decided', 'not', 'to', 'rest', 'on', 'their', 'laurels', 'the', 'last', 'few', 'years', 'have', 'seen', 'the', 'steady', 'introduction', 'of', 'technology', 'into', 'the', 'world', 'of', 'sports', 'amplifying', 'fans', 'appreciation', 'of', 'games', 'enhancing', 'athletes', 'public', 'profiles', 'and', 'informing', 'their', 'training', 'methods', 'even', 'influencing', 'how', 'contests', 'are', 'waged', 'also', 'digital', 'technology', 'in', 'particular', 'has', 'helped', 'to', 'create', 'an', 'alternative', 'source', 'of', 'revenue', 'besides', 'the', 'games', 'themselves', 'corporate', 'sponsorship', 'they', 'achieved', 'this', 'by', 'capitalizing', 'on', 'the', 'ardor', 'of', 'their', 'customer', 'base', 'sorry', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tokenizer = CountVectorizer().build_tokenizer()\n",
    "# convert to lowercase, then tokenize\n",
    "tokens1 = tokenizer(doc1.lower())\n",
    "print(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tjthanapat\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tjthanapat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tjthanapat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tjthanapat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", 'the']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_word_tokenizer(\"' the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st', 'Century', 'Sports', 'How', 'Digital', 'Technology', 'Is', 'Changing', 'the', 'Face', 'Of', 'The', 'Sporting', 'Industry', 'The', 'sporting', 'industry', 'has', 'come', 'long', 'way', 'since', 'the', '60s', 'It', 'has', 'carved', 'out', 'for', 'itself', 'niche', 'with', 'its', 'roots', 'so', 'deep', 'that', 'cannot', 'fathom', 'the', 'sports', 'industry', 'showing', 'any', 'sign', 'of', 'decline', 'any', 'time', 'soon', 'or', 'later', 'The', 'reason', 'can', 'be', 'found', 'in', 'this', 'seemingly', 'subtle', 'difference', 'other', 'industries', 'have', 'customers', 'the', 'sporting', 'industry', 'has', 'fans', 'Vivek', 'Ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'NBA', 'Sacramento', 'Kings', 'explained', 'it', 'beautifully', 'Fans', 'will', 'paint', 'their', 'face', 'purple', 'fans', 'will', 'evangelize', 'Every', 'other', 'CEO', 'in', 'every', 'business', 'is', 'dying', 'to', 'be', 'in', 'our', 'position', 'they', 're', 'dying', 'to', 'have', 'fans', 'While', 'fan', 'passion', 'alone', 'could', 'almost', 'certainly', 'keep', 'the', 'industry', 'going', 'leagues', 'and', 'sporting', 'franchises', 'have', 'decided', 'not', 'to', 'rest', 'on', 'their', 'laurels', 'The', 'last', 'few', 'years', 'have', 'seen', 'the', 'steady', 'introduction', 'of', 'technology', 'into', 'the', 'world', 'of', 'sports', 'amplifying', 'fans', 'appreciation', 'of', 'games', 'enhancing', 'athletes', 'public', 'profiles', 'and', 'informing', 'their', 'training', 'methods', 'even', 'influencing', 'how', 'contests', 'are', 'waged', 'Also', 'digital', 'technology', 'in', 'particular', 'has', 'helped', 'to', 'create', 'an', 'alternative', 'source', 'of', 'revenue', 'besides', 'the', 'games', 'themselves', 'corporate', 'sponsorship', 'They', 'achieved', 'this', 'by', 'capitalizing', 'on', 'the', 'ardor', 'of', 'their', 'customer', 'base', 'sorry', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CountVectorizer(stop_words='english').build_tokenizer()\n",
    "tokens = tokenizer(doc1)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'any', 'if', 'yourselves', 'which', 'themselves', 'side', 'through', 'amoungst', 'name', 'whose', 'under', 'seems', 'whole', 'about', 'whoever', 'also', 'take', 'hasnt', 'should', 'same', 'against', 'last', 'have', 'inc', 'elsewhere', 'off', 'everyone', 're', 'within', 'all', 'neither', 'than', 'towards', 'please', 'seemed', 'everywhere', 'con', 'five', 'eight', 'again', 'cant', 'only', 'whatever', 'due', 'show', 'made', 'first', 'ourselves', 'somehow', 'per', 'herself', 'indeed', 'thence', 'etc', 'ltd', 'other', 'they', 'am', 'on', 'beside', 'thus', 'so', 'myself', 'into', 'up', 'almost', 'whom', 'is', 'enough', 'further', 'himself', 'un', 'anyway', 'itself', 'with', 'rather', 'less', 'afterwards', 'it', 'your', 'around', 'fifty', 'cannot', 'something', 'still', 'we', 'throughout', 'no', 'part', 'thereafter', 'nothing', 'be', 'thin', 'nowhere', 'toward', 'been', 'onto', 'can', 'otherwise', 'co', 'to', 'were', 'you', 'mill', 'hereupon', 'because', 'i', 'him', 'whereby', 'not', 'for', 'sincere', 'well', 'hence', 'me', 'next', 'behind', 'done', 'one', 'herein', 'that', 'ie', 'whereafter', 'nobody', 'empty', 'as', 'fire', 'forty', 'could', 'three', 'anywhere', 'seeming', 'whereas', 'several', 'wherever', 'are', 'six', 'those', 'nevertheless', 'least', 'why', 'anyone', 'own', 'amount', 'may', 'these', 'though', 'top', 'from', 'its', 'hereby', 'here', 'put', 'moreover', 'she', 'front', 'by', 'system', 'beforehand', 'whether', 'then', 'describe', 'anything', 'hereafter', 'twelve', 'mine', 'give', 'back', 'latter', 'never', 'nor', 'of', 'fill', 'where', 'upon', 'every', 'move', 'third', 'how', 'whereupon', 'among', 'thru', 'none', 'he', 'amongst', 'therein', 'somewhere', 'bill', 'sometime', 'whenever', 'others', 'whence', 'get', 'sometimes', 'them', 'although', 'often', 'latterly', 'some', 'his', 'call', 'much', 'more', 'however', 'being', 'yourself', 'meanwhile', 'this', 'former', 'at', 'each', 'their', 'during', 'perhaps', 'between', 'too', 'except', 'thick', 'noone', 'already', 'eleven', 'becomes', 'and', 'beyond', 'besides', 'most', 'go', 'after', 'an', 'together', 'everything', 'thereby', 'twenty', 'has', 'above', 'always', 'since', 'such', 'along', 'what', 'had', 'the', 'found', 'a', 'de', 'wherein', 'even', 'thereupon', 'couldnt', 'hundred', 'sixty', 'serious', 'ever', 'who', 'via', 'must', 'or', 'hers', 'cry', 'very', 'while', 'nine', 'see', 'full', 'over', 'across', 'namely', 'else', 'either', 'her', 'do', 'interest', 'someone', 'ten', 'become', 'will', 'might', 'anyhow', 'would', 'when', 'bottom', 'down', 'becoming', 'became', 'few', 'mostly', 'until', 'in', 'now', 'therefore', 'fifteen', 'detail', 'without', 'both', 'our', 'below', 'four', 'but', 'formerly', 'eg', 'whither', 'yet', 'find', 'once', 'us', 'was', 'alone', 'many', 'seem', 'before', 'yours', 'another', 'there', 'two', 'my', 'ours', 'out', 'keep'})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "stop_words = set(stopwords.words('english')).union(ENGLISH_STOP_WORDS)\n",
    "\n",
    "def nltk_word_tokenizer1(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = word_tokenize(text)\n",
    "  tokens_to_return = list()\n",
    "  for token in tokens:\n",
    "    if(re.match(r\"[\\w'-]+\", token) and (token not in ['-',\"'\"]) and (token not in stop_words)):\n",
    "      tokens_to_return.append(token)\n",
    "  \n",
    "  return tokens_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def porter_stem_tokenizer(text):\n",
    "  tokens = nltk_word_tokenizer(text.lower())\n",
    "  stemmer = PorterStemmer()\n",
    "  stems = list()\n",
    "  for token in tokens:\n",
    "    stems.append(stemmer.stem(token))\n",
    "  return stems\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer as SnowballStemmer\n",
    "\n",
    "def snowball_stem_tokenizer(text):\n",
    "  tokens = nltk_word_tokenizer(text.lower())\n",
    "  stemmer = SnowballStemmer()\n",
    "  stems = list()\n",
    "  for token in tokens:\n",
    "    stems.append(stemmer.stem(token))\n",
    "  return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "def lancaster_stem_tokenizer(text):\n",
    "  tokens = nltk_word_tokenizer(text.lower())\n",
    "  stemmer = LancasterStemmer()\n",
    "  stems = list()\n",
    "  for token in tokens:\n",
    "    stems.append(stemmer.stem(token))\n",
    "  return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st-centuri', 'sport', 'how', 'digit', 'technolog', 'is', 'chang', 'the', 'face', 'of', 'the', 'sport', 'industri', 'the', 'sport', 'industri', 'ha', 'come', 'a', 'long', 'way', 'sinc', 'the', '60', 'it', 'ha', 'carv', 'out', 'for', 'itself', 'a', 'nich', 'with', 'it', 'root', 'so', 'deep', 'that', 'i', 'can', 'not', 'fathom', 'the', 'sport', 'industri', 'show', 'ani', 'sign', 'of', 'declin', 'ani', 'time', 'soon', 'or', 'later', 'the', 'reason', 'can', 'be', 'found', 'in', 'thi', 'seemingli', 'subtl', 'differ', 'other', 'industri', 'have', 'custom', 'the', 'sport', 'industri', 'ha', 'fan', 'vivek', 'ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'nba', 's', 'sacramento', 'king', 'explain', 'it', 'beauti', 'fan', 'will', 'paint', 'their', 'face', 'purpl', 'fan', 'will', 'evangel', 'everi', 'other', 'ceo', 'in', 'everi', 'busi', 'is', 'die', 'to', 'be', 'in', 'our', 'posit', 'they', 're', 'die', 'to', 'have', 'fans.', 'while', 'fan', 'passion', 'alon', 'could', 'almost', 'certainli', 'keep', 'the', 'industri', 'go', 'leagu', 'and', 'sport', 'franchis', 'have', 'decid', 'not', 'to', 'rest', 'on', 'their', 'laurel', 'the', 'last', 'few', 'year', 'have', 'seen', 'the', 'steadi', 'introduct', 'of', 'technolog', 'into', 'the', 'world', 'of', 'sport', 'amplifi', 'fan', 'appreci', 'of', 'game', 'enhanc', 'athlet', 'public', 'profil', 'and', 'inform', 'their', 'train', 'method', 'even', 'influenc', 'how', 'contest', 'are', 'wage', 'also', 'digit', 'technolog', 'in', 'particular', 'ha', 'help', 'to', 'creat', 'an', 'altern', 'sourc', 'of', 'revenu', 'besid', 'the', 'game', 'themselv', 'corpor', 'sponsorship', 'they', 'achiev', 'thi', 'by', 'capit', 'on', 'the', 'ardor', 'of', 'their', 'custom', 'base', 'sorri', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "print(porter_stem_tokenizer(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st-centuri', 'sport', 'how', 'digit', 'technolog', 'is', 'chang', 'the', 'face', 'of', 'the', 'sport', 'industri', 'the', 'sport', 'industri', 'has', 'come', 'a', 'long', 'way', 'sinc', 'the', '60s', 'it', 'has', 'carv', 'out', 'for', 'itself', 'a', 'nich', 'with', 'it', 'root', 'so', 'deep', 'that', 'i', 'can', 'not', 'fathom', 'the', 'sport', 'industri', 'show', 'ani', 'sign', 'of', 'declin', 'ani', 'time', 'soon', 'or', 'later', 'the', 'reason', 'can', 'be', 'found', 'in', 'this', 'seem', 'subtl', 'differ', 'other', 'industri', 'have', 'custom', 'the', 'sport', 'industri', 'has', 'fan', 'vivek', 'ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'nba', 's', 'sacramento', 'king', 'explain', 'it', 'beauti', 'fan', 'will', 'paint', 'their', 'face', 'purpl', 'fan', 'will', 'evangel', 'everi', 'other', 'ceo', 'in', 'everi', 'busi', 'is', 'die', 'to', 'be', 'in', 'our', 'posit', 'they', 're', 'die', 'to', 'have', 'fans.', 'while', 'fan', 'passion', 'alon', 'could', 'almost', 'certain', 'keep', 'the', 'industri', 'go', 'leagu', 'and', 'sport', 'franchis', 'have', 'decid', 'not', 'to', 'rest', 'on', 'their', 'laurel', 'the', 'last', 'few', 'year', 'have', 'seen', 'the', 'steadi', 'introduct', 'of', 'technolog', 'into', 'the', 'world', 'of', 'sport', 'amplifi', 'fan', 'appreci', 'of', 'game', 'enhanc', 'athlet', 'public', 'profil', 'and', 'inform', 'their', 'train', 'method', 'even', 'influenc', 'how', 'contest', 'are', 'wage', 'also', 'digit', 'technolog', 'in', 'particular', 'has', 'help', 'to', 'creat', 'an', 'altern', 'sourc', 'of', 'revenu', 'besid', 'the', 'game', 'themselv', 'corpor', 'sponsorship', 'they', 'achiev', 'this', 'by', 'capit', 'on', 'the', 'ardor', 'of', 'their', 'custom', 'base', 'sorri', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "print(snowball_stem_tokenizer(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st-century', 'sport', 'how', 'digit', 'technolog', 'is', 'chang', 'the', 'fac', 'of', 'the', 'sport', 'industry', 'the', 'sport', 'industry', 'has', 'com', 'a', 'long', 'way', 'sint', 'the', '60s', 'it', 'has', 'carv', 'out', 'for', 'itself', 'a', 'nich', 'with', 'it', 'root', 'so', 'deep', 'that', 'i', 'can', 'not', 'fathom', 'the', 'sport', 'industry', 'show', 'any', 'sign', 'of', 'declin', 'any', 'tim', 'soon', 'or', 'lat', 'the', 'reason', 'can', 'be', 'found', 'in', 'thi', 'seem', 'subtl', 'diff', 'oth', 'industry', 'hav', 'custom', 'the', 'sport', 'industry', 'has', 'fan', 'vivek', 'ranadivé', 'lead', 'of', 'the', 'own', 'group', 'of', 'the', 'nba', 's', 'sacramento', 'king', 'explain', 'it', 'beauty', 'fan', 'wil', 'paint', 'their', 'fac', 'purpl', 'fan', 'wil', 'evangel', 'every', 'oth', 'ceo', 'in', 'every', 'busy', 'is', 'dying', 'to', 'be', 'in', 'our', 'posit', 'they', 're', 'dying', 'to', 'hav', 'fans.', 'whil', 'fan', 'pass', 'alon', 'could', 'almost', 'certain', 'keep', 'the', 'industry', 'going', 'leagu', 'and', 'sport', 'franch', 'hav', 'decid', 'not', 'to', 'rest', 'on', 'their', 'laurel', 'the', 'last', 'few', 'year', 'hav', 'seen', 'the', 'steady', 'introduc', 'of', 'technolog', 'into', 'the', 'world', 'of', 'sport', 'ampl', 'fan', 'apprecy', 'of', 'gam', 'enh', 'athlet', 'publ', 'profil', 'and', 'inform', 'their', 'train', 'method', 'ev', 'influ', 'how', 'contest', 'ar', 'wag', 'also', 'digit', 'technolog', 'in', 'particul', 'has', 'help', 'to', 'cre', 'an', 'altern', 'sourc', 'of', 'revenu', 'besid', 'the', 'gam', 'themselv', 'corp', 'spons', 'they', 'achiev', 'thi', 'by', 'capit', 'on', 'the', 'ard', 'of', 'their', 'custom', 'bas', 'sorry', 'fan', 'bas']\n"
     ]
    }
   ],
   "source": [
    "print(lancaster_stem_tokenizer(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def wordnet_lemma_tokenizer(text):\n",
    "  tokens = nltk_word_tokenizer(text.lower())\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  lemmas = list()\n",
    "  for token in tokens:\n",
    "    lemmas.append(lemmatizer.lemmatize(token))\n",
    "  return lemmas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st-century', 'sport', 'how', 'digital', 'technology', 'is', 'changing', 'the', 'face', 'of', 'the', 'sporting', 'industry', 'the', 'sporting', 'industry', 'ha', 'come', 'a', 'long', 'way', 'since', 'the', '60', 'it', 'ha', 'carved', 'out', 'for', 'itself', 'a', 'niche', 'with', 'it', 'root', 'so', 'deep', 'that', 'i', 'can', 'not', 'fathom', 'the', 'sport', 'industry', 'showing', 'any', 'sign', 'of', 'decline', 'any', 'time', 'soon', 'or', 'later', 'the', 'reason', 'can', 'be', 'found', 'in', 'this', 'seemingly', 'subtle', 'difference', 'other', 'industry', 'have', 'customer', 'the', 'sporting', 'industry', 'ha', 'fan', 'vivek', 'ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'nba', 's', 'sacramento', 'king', 'explained', 'it', 'beautifully', 'fan', 'will', 'paint', 'their', 'face', 'purple', 'fan', 'will', 'evangelize', 'every', 'other', 'ceo', 'in', 'every', 'business', 'is', 'dying', 'to', 'be', 'in', 'our', 'position', 'they', 're', 'dying', 'to', 'have', 'fans.', 'while', 'fan', 'passion', 'alone', 'could', 'almost', 'certainly', 'keep', 'the', 'industry', 'going', 'league', 'and', 'sporting', 'franchise', 'have', 'decided', 'not', 'to', 'rest', 'on', 'their', 'laurel', 'the', 'last', 'few', 'year', 'have', 'seen', 'the', 'steady', 'introduction', 'of', 'technology', 'into', 'the', 'world', 'of', 'sport', 'amplifying', 'fan', 'appreciation', 'of', 'game', 'enhancing', 'athlete', 'public', 'profile', 'and', 'informing', 'their', 'training', 'method', 'even', 'influencing', 'how', 'contest', 'are', 'waged', 'also', 'digital', 'technology', 'in', 'particular', 'ha', 'helped', 'to', 'create', 'an', 'alternative', 'source', 'of', 'revenue', 'besides', 'the', 'game', 'themselves', 'corporate', 'sponsorship', 'they', 'achieved', 'this', 'by', 'capitalizing', 'on', 'the', 'ardor', 'of', 'their', 'customer', 'base', 'sorry', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemma_tokenizer(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag):\n",
    "  if tag[0] == 'V':\n",
    "    return 'v'\n",
    "  elif tag[0] == 'J':\n",
    "    return 'a'\n",
    "  elif tag[0] == 'R':\n",
    "    return 'r'\n",
    "  else:\n",
    "    return 'n'\n",
    "\n",
    "def wordnet_lemma_pos_tokenizer(text):\n",
    "  tokens = nltk_word_tokenizer(text.lower())\n",
    "  tokens_with_pos_tag = nltk.pos_tag(tokens)\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  lemma_tokens = list()\n",
    "  for token in tokens_with_pos_tag:\n",
    "    word = token[0]\n",
    "    pos = convert_tag(token[1])\n",
    "    lemma_tokens.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "  return lemma_tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21st', 'century', 'sport', 'how', 'digital', 'technology', 'be', 'change', 'the', 'face', 'of', 'the', 'sporting', 'industry', 'the', 'sporting', 'industry', 'have', 'come', 'long', 'way', 'since', 'the', '60', 'it', 'have', 'carve', 'out', 'for', 'itself', 'niche', 'with', 'it', 'root', 'so', 'deep', 'that', 'cannot', 'fathom', 'the', 'sport', 'industry', 'show', 'any', 'sign', 'of', 'decline', 'any', 'time', 'soon', 'or', 'later', 'the', 'reason', 'can', 'be', 'find', 'in', 'this', 'seemingly', 'subtle', 'difference', 'other', 'industry', 'have', 'customer', 'the', 'sporting', 'industry', 'have', 'fan', 'vivek', 'ranadivé', 'leader', 'of', 'the', 'ownership', 'group', 'of', 'the', 'nba', 'sacramento', 'king', 'explain', 'it', 'beautifully', 'fan', 'will', 'paint', 'their', 'face', 'purple', 'fan', 'will', 'evangelize', 'every', 'other', 'ceo', 'in', 'every', 'business', 'be', 'die', 'to', 'be', 'in', 'our', 'position', 'they', 're', 'die', 'to', 'have', 'fan', 'while', 'fan', 'passion', 'alone', 'could', 'almost', 'certainly', 'keep', 'the', 'industry', 'go', 'league', 'and', 'sport', 'franchise', 'have', 'decide', 'not', 'to', 'rest', 'on', 'their', 'laurel', 'the', 'last', 'few', 'year', 'have', 'see', 'the', 'steady', 'introduction', 'of', 'technology', 'into', 'the', 'world', 'of', 'sport', 'amplify', 'fan', 'appreciation', 'of', 'game', 'enhance', 'athlete', 'public', 'profile', 'and', 'inform', 'their', 'training', 'method', 'even', 'influence', 'how', 'contest', 'be', 'wag', 'also', 'digital', 'technology', 'in', 'particular', 'have', 'help', 'to', 'create', 'an', 'alternative', 'source', 'of', 'revenue', 'besides', 'the', 'game', 'themselves', 'corporate', 'sponsorship', 'they', 'achieve', 'this', 'by', 'capitalize', 'on', 'the', 'ardor', 'of', 'their', 'customer', 'base', 'sorry', 'fan', 'base']\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemma_pos_tokenizer(doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lancaster_stem_tokenizer,\n",
    "                             min_df=0.01)\n",
    "X = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2381\n"
     ]
    }
   ],
   "source": [
    "print(len(list(vectorizer.vocabulary_.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fe7d652243bcdb6cde2e69617dc664bf14361ea2de14b139d2fec55ec2ae7e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
