{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Task 1\n",
    "\n",
    "โดย\n",
    "\n",
    "ตุลธร วงศ์ชัย รหัสนักศึกษา 63070224\n",
    "\n",
    "ธนภัทร ธีรรัตตัญญู รหัสนักศึกษา 63070227\n",
    "\n",
    "> **README**:\n",
    "> - 'Run all' is not recommended. \n",
    "> - Section 1 must be run before any other section.\n",
    "> - Read and follow instruction of each section carefully if it is provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Init Project\n",
    "\n",
    "> **Instruction**: Set `ROOT_PATH` before running this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Set Root Path\n",
    "\n",
    "* If you initialize this project for first time, run code cell R1\n",
    "* Otherwise, set your own root path in code cell R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Code Cell R1 ###\n",
    "\n",
    "# ROOT_PATH = os.getcwd() # Get current working directory\n",
    "\n",
    "# # Create /data directory\n",
    "# data_dir = os.path.join(ROOT_PATH, 'data')\n",
    "# os.mkdir(data_dir) \n",
    "\n",
    "# # Create /data/raw directory\n",
    "# data_target_dir = os.path.join(ROOT_PATH, 'data/raw')\n",
    "# os.mkdir(data_target_dir)\n",
    "\n",
    "# # Create /data/datastore directory\n",
    "# data_datastore_dir = os.path.join(ROOT_PATH, 'data/datastore')\n",
    "# os.mkdir(data_datastore_dir) \n",
    "\n",
    "# # Create /data/target directory\n",
    "# data_target_dir = os.path.join(ROOT_PATH, 'data/target')\n",
    "# os.mkdir(data_target_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell R2 ###\n",
    "\n",
    "# Set your own root path here\n",
    "ROOT_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Scraping from Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 กำหนดค่าคงที่และสร้างฟังก์ชันทีใช้งานบ่อย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 กำหนดค่าคงที่ BASE_URL ตามเซลล์โค้ดที่ 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.1.1 ###\n",
    "\n",
    "BASE_URL = 'http://www.it.kmitl.ac.th/~teerapong/news_archive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 สร้างฟังก์ชันสำหรับส่ง GET request ไปยัง URL ที่ต้องการ พร้อมตรวจสอบว่าการส่งนั้นสำเร็จหรือไม่ (มี status เป็น 200) ถ้าไม่สำเร็จ ให้ทำการ raise Exception ตามเซลล์โค้ดที่ 2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.1.2 ###\n",
    "\n",
    "def get_request(url:str,**kwargs)->requests.models.Response:\n",
    "  \"\"\"\n",
    "  Call GET request using requests package \n",
    "  then return response if it is successful (status 200)\n",
    "  otherwise throw an exception.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  url : str\n",
    "    URL to request\n",
    "  **kwargs\n",
    "    Other parameters for requests.get\n",
    "\n",
    "  Returns\n",
    "  ----------\n",
    "  requests.models.Response\n",
    "    Response of the request\n",
    "  \"\"\"\n",
    "  res = requests.get(url, **kwargs)\n",
    "\n",
    "  # If the request is not successful, throw an exception.  \n",
    "  if (res.status_code != 200):\n",
    "    print(res.text)\n",
    "    err = Exception('The request is not successful. ' + \n",
    "                    f'Its status code is {res.status_code}. ' + \n",
    "                    f'The URL of request is {res.url}')\n",
    "    raise err\n",
    "  else:\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 เก็บ URL ของหน้ารวมบทความข่าวแต่ละเดือน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 request หน้า index ของ News Article Archive และแปลงด้วย BeautifulSoup ตามเซลล์โค้ดที่ 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>Online News Archive</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<meta content=\"noindex\" name=\"robots\"/>\n",
       "<meta content=\"news,articles,news\" name=\"keywords\"/>\n",
       "<meta content=\"Breaking News | International Headlines\" property=\"og:title\"/>\n",
       "<meta content=\"News Archive\" property=\"og:site_name\"/>\n",
       "<meta content=\"Latest news and more from the definitive brand of quality news.\" property=\"og:description\"/>\n",
       "<link href=\"css/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
       "<script src=\"js/jquery-3.2.1.slim.min.js\"></script>\n",
       "<script src=\"js/popper.min.js\"></script>\n",
       "<script src=\"js/tether.min.js\"></script>\n",
       "<script src=\"js/jquery-3.2.1.slim.min.js\"></script>\n",
       "<script src=\"js/popper.min.js\"></script>\n",
       "<script src=\"js/tether.min.js\"></script>\n",
       "<script src=\"js/bootstrap.min.js\"></script>\n",
       "<style>\n",
       "\t  \t\t.main{ padding: 0; text-align: center;}\n",
       "\t  \t\t.footer{ padding: 6px;text-align: center; margin-top: 1em; }\n",
       "\n",
       "\t  \t\th1\n",
       "\t  \t\t{\n",
       "\t  \t\t\tfont-size: 180%;\n",
       "\t  \t\t\tmargin-top: 15px;\n",
       "\t  \t\t\tmargin-bottom: 15px;\n",
       "\t  \t\t}\n",
       "\t  \t\tul {list-style-type: none;}\n",
       "\t  \t\tli { margin-top: 5px; }\n",
       "\t  </style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"container\" style=\"margin-top: 2em;\">\n",
       "<div class=\"main\">\n",
       "<img alt=\"banner\" src=\"images/banner.jpg\" width=\"500\"/>\n",
       "<h1>News Article Archive</h1>\n",
       "<p>Archive of all news headlines and stories, organised per month.</p>\n",
       "<ul>\n",
       "<li>Articles — <a href=\"month-jan-2017.html\">January</a> [118]</li>\n",
       "<li>Articles — <a href=\"month-feb-2017.html\">February</a> [124]</li>\n",
       "<li>Articles — <a href=\"month-mar-2017.html\">March</a> [116]</li>\n",
       "<li>Articles — <a href=\"month-apr-2017.html\">April</a> [118]</li>\n",
       "<li>Articles — <a href=\"month-may-2017.html\">May</a> [115]</li>\n",
       "<li>Articles — <a href=\"month-jun-2017.html\">June</a> [115]</li>\n",
       "<li>Articles — <a href=\"month-jul-2017.html\">July</a> [122]</li>\n",
       "<li>Articles — <a href=\"month-aug-2017.html\">August</a> [116]</li>\n",
       "<li>Articles — <a href=\"month-sep-2017.html\">September</a> [113]</li>\n",
       "<li>Articles — <a href=\"month-oct-2017.html\">October</a> [124]</li>\n",
       "<li>Articles — <a href=\"month-nov-2017.html\">November</a> [122]</li>\n",
       "<li>Articles — <a href=\"month-dec-2017.html\">December</a> [115]</li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"footer\">\n",
       "<span><a href=\"#\">Terms &amp; Conditions</a> | <a href=\"#\">Privacy Policy</a> | <a href=\"#\">Cookie Information</a> </span><br/>\n",
       "<span>© <span class=\"thisyear\">2019-2020</span> — Original rights holders</span>\n",
       "</div>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 2.2.1 ###\n",
    "\n",
    "index_url = BASE_URL + 'index.html'\n",
    "res = get_request(index_url)\n",
    "index_page = BeautifulSoup(res.content, 'lxml') # Parse the response\n",
    "index_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2 เนื่องจากในหน้า index จะมีรายการของเดือนที่มีทั้งหมดอยู่ใน `<li>` ซึ่งเชื่อมไปยังหน้ารวมบทความข่าวของเดือนนั้น ๆ จึงทำการดึง `<li>` tag ตามเซลล์โค้ดที่ 2.2.2.1 จากนั้นทำการดึงค่าของ `href` ของ `<a>` ที่อยู่ในแต่ละ `<li>` tag ที่ได้มา ตามเซลล์โค้ดที่ 2.2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>Articles — <a href=\"month-jan-2017.html\">January</a> [118]</li>,\n",
       " <li>Articles — <a href=\"month-feb-2017.html\">February</a> [124]</li>,\n",
       " <li>Articles — <a href=\"month-mar-2017.html\">March</a> [116]</li>,\n",
       " <li>Articles — <a href=\"month-apr-2017.html\">April</a> [118]</li>,\n",
       " <li>Articles — <a href=\"month-may-2017.html\">May</a> [115]</li>,\n",
       " <li>Articles — <a href=\"month-jun-2017.html\">June</a> [115]</li>,\n",
       " <li>Articles — <a href=\"month-jul-2017.html\">July</a> [122]</li>,\n",
       " <li>Articles — <a href=\"month-aug-2017.html\">August</a> [116]</li>,\n",
       " <li>Articles — <a href=\"month-sep-2017.html\">September</a> [113]</li>,\n",
       " <li>Articles — <a href=\"month-oct-2017.html\">October</a> [124]</li>,\n",
       " <li>Articles — <a href=\"month-nov-2017.html\">November</a> [122]</li>,\n",
       " <li>Articles — <a href=\"month-dec-2017.html\">December</a> [115]</li>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cell Code 2.2.2.1  ###\n",
    "\n",
    "tags = index_page.select('li')\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month-jan-2017.html\n",
      "month-feb-2017.html\n",
      "month-mar-2017.html\n",
      "month-apr-2017.html\n",
      "month-may-2017.html\n",
      "month-jun-2017.html\n",
      "month-jul-2017.html\n",
      "month-aug-2017.html\n",
      "month-sep-2017.html\n",
      "month-oct-2017.html\n",
      "month-nov-2017.html\n",
      "month-dec-2017.html\n"
     ]
    }
   ],
   "source": [
    "### Cell Code 2.2.2.2  ###\n",
    "\n",
    "month_links = list()\n",
    "for tag in tags:\n",
    "  link = tag.find('a')['href']\n",
    "  month_links.append(link)\n",
    "  print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 เก็บข้อมูลหมวดหมู่และ URL ของบทความข่าวในแต่ละเดือน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_month_page(month_url):\n",
    "  \"\"\"\n",
    "  Scrape title, category and link of available news articles from month page.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  month_url : str\n",
    "    URL of month page\n",
    "\n",
    "  Returns\n",
    "  ----------\n",
    "  DataFrame\n",
    "    DataFrame containing title, category and link of news articles\n",
    "  \"\"\"\n",
    "\n",
    "  res = get_request(month_url)\n",
    "  month_page = BeautifulSoup(res.content, 'lxml') # Parse the response\n",
    "  \n",
    "  articles = month_page.select('tbody>tr')\n",
    "\n",
    "  article_titles = list()\n",
    "  article_categories = list()\n",
    "  article_links = list()\n",
    "\n",
    "  for article in articles:\n",
    "    category = article.select_one('td.category').string.strip()\n",
    "    if (category!='N/A'):\n",
    "      title = article.select_one('td.title>a').string\n",
    "      link = article.select_one('td.title>a')['href']\n",
    "      article_titles.append(title)\n",
    "      article_categories.append(category)\n",
    "      article_links.append(link)\n",
    "  \n",
    "  articles_df = pd.DataFrame({'title':article_titles,\n",
    "                              'category':article_categories,\n",
    "                              'link':article_links})  \n",
    "  return articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jan-2017.html\n",
      "Scraped 118 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_01.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-feb-2017.html\n",
      "Scraped 122 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_02.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-mar-2017.html\n",
      "Scraped 116 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_03.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-apr-2017.html\n",
      "Scraped 117 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_04.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-may-2017.html\n",
      "Scraped 114 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_05.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jun-2017.html\n",
      "Scraped 114 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_06.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jul-2017.html\n",
      "Scraped 122 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_07.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-aug-2017.html\n",
      "Scraped 116 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_08.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-sep-2017.html\n",
      "Scraped 112 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_09.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-oct-2017.html\n",
      "Scraped 122 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_10.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-nov-2017.html\n",
      "Scraped 121 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_11.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-dec-2017.html\n",
      "Scraped 114 article links\n",
      "Saved to ROOT_PATH/data/raw/article_links_2017_12.csv\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "month_abbr_to_number = {\n",
    "  'jan':'01',\n",
    "  'feb':'02',\n",
    "  'mar':'03',\n",
    "  'apr':'04',\n",
    "  'may':'05',\n",
    "  'jun':'06',\n",
    "  'jul':'07',\n",
    "  'aug':'08',\n",
    "  'sep':'09',\n",
    "  'oct':'10',\n",
    "  'nov':'11',\n",
    "  'dec':'12'\n",
    "}\n",
    "\n",
    "for month_link in month_links:\n",
    "  \n",
    "  month_url = BASE_URL + month_link\n",
    "  print(f'Scraping {month_url}')\n",
    "  articles_df = scrape_month_page(month_url)\n",
    "  print(f'Scraped {articles_df.shape[0]} article links')\n",
    "\n",
    "  month = month_link[6:9] # Get month abbriviation from month_link\n",
    "  month = month_abbr_to_number[month] # Convert to month number\n",
    "  year = month_link[10:14] # Get year from month_link\n",
    "  file_name = f'article_links_{year}_{month}.csv'\n",
    "  file_path = f'{ROOT_PATH}/data/raw/{file_name}'\n",
    "  articles_df.to_csv(file_path, index=False)\n",
    "  print(f'Saved to ROOT_PATH/data/raw/{file_name}')\n",
    "  print('-'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 เก็บข้อมูลจากหน้าบทความข่าว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['article_links_2017_01.csv',\n",
       " 'article_links_2017_02.csv',\n",
       " 'article_links_2017_03.csv',\n",
       " 'article_links_2017_04.csv',\n",
       " 'article_links_2017_05.csv',\n",
       " 'article_links_2017_06.csv',\n",
       " 'article_links_2017_07.csv',\n",
       " 'article_links_2017_08.csv',\n",
       " 'article_links_2017_09.csv',\n",
       " 'article_links_2017_10.csv',\n",
       " 'article_links_2017_11.csv',\n",
       " 'article_links_2017_12.csv']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_links_month_files = os.listdir(f'{ROOT_PATH}/data/raw')\n",
    "article_links_month_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_article_page(article_url):\n",
    "  \"\"\"\n",
    "  Scrape article content from news article page with a given URL.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  article_url : str\n",
    "    URL of article page\n",
    "\n",
    "  Returns\n",
    "  ----------\n",
    "  str\n",
    "    Article content\n",
    "  \"\"\"\n",
    "\n",
    "  res = get_request(article_url)\n",
    "  article_page = BeautifulSoup(res.content, 'lxml') # Parse the response\n",
    "\n",
    "\n",
    "  # Get content of article, which is in p tags without 'notice' class \n",
    "  # in div.main\n",
    "  p_tags = article_page.select('div.main>p:not(.notice)')\n",
    "\n",
    "  # Every article repeats its title in content section.\n",
    "  # Due to inconsistent formating style, some articles repeat in b tag\n",
    "  # while some repeat in p tag. In the later case, remove first item of\n",
    "  # selected p_tags.\n",
    "  b_tags = article_page.select('div.main>b')\n",
    "  # If there is no b tag in content section, remove first item of\n",
    "  # selected p_tags\n",
    "  if (len(b_tags)==0):\n",
    "    p_tags.pop(0)\n",
    "  \n",
    "  article_content = ''\n",
    "  # Concatenate all paragraphs\n",
    "  for p in p_tags:\n",
    "    article_content = article_content + ' ' + p.text\n",
    "\n",
    "  # Replace double space with single space and \n",
    "  # remove leading and trailing whitespace\n",
    "  article_content = article_content.replace('  ',' ').strip() \n",
    "\n",
    "  return article_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all contents to datestore folder\n",
    "for article_links_month in article_links_month_files:\n",
    "  article_df = pd.read_csv(f'{ROOT_PATH}/data/raw/{article_links_month}')\n",
    "  article_contents = list()\n",
    "  for _, article in article_df.iterrows():\n",
    "    article_link = article['link']\n",
    "    article_url = BASE_URL + article_link\n",
    "    article_content = scrape_article_page(article_url)\n",
    "    article_contents.append(article_content)\n",
    "\n",
    "  article_contents_df = pd.DataFrame({'content':article_contents})\n",
    "  article_contents_df.to_csv(f'{ROOT_PATH}/data/datastore/article_contents_{article_links_month[14:21]}.txt',sep='\\n',\n",
    "    index=False,header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all category to target folder\n",
    "for article_links_month in article_links_month_files:\n",
    "    df = pd.read_csv(f'{ROOT_PATH}/data/raw/{article_links_month}')\n",
    "    df['category'].to_csv(f'{ROOT_PATH}/data/target/article_targets_{article_links_month[14:21]}.txt',sep='\\n',\n",
    "  index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tunza\\AppData\\Local\\Temp\\ipykernel_11396\\2088313385.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(f'{ROOT_PATH}/data/datastore/article_contents_2017_01.txt',header=None, delimiter=\"\\r\\n\", names=['content'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sporting industry has come a long way sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Shares in Europe's leading reinsurers and tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"BT is offering customers free internet teleph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Shares in UK banking group Barclays have rise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"England centre Olly Barkley has been passed f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>\"Former Worldcom boss Bernie Ebbers, who is ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>\"Details of the next generation of Microsoft's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>\"Microsoft has said it will replace more than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\"Yangtze Electric Power, the operator of China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>\"A judge has dismissed an attempt by Russian o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "0    The sporting industry has come a long way sinc...\n",
       "1    \"Shares in Europe's leading reinsurers and tra...\n",
       "2    \"BT is offering customers free internet teleph...\n",
       "3    \"Shares in UK banking group Barclays have rise...\n",
       "4    \"England centre Olly Barkley has been passed f...\n",
       "..                                                 ...\n",
       "113  \"Former Worldcom boss Bernie Ebbers, who is ac...\n",
       "114  \"Details of the next generation of Microsoft's...\n",
       "115  \"Microsoft has said it will replace more than ...\n",
       "116  \"Yangtze Electric Power, the operator of China...\n",
       "117  \"A judge has dismissed an attempt by Russian o...\n",
       "\n",
       "[118 rows x 1 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{ROOT_PATH}/data/datastore/article_contents_2017_01.txt',header=None, delimiter=\"\\r\\n\", names=['content'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d853cb24e8f7628e3ba29dc09518236c084a73039b3bc92092f3293b2fe13772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
