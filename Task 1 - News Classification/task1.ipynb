{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Task 1\n",
    "\n",
    "โดย\n",
    "\n",
    "ตุลธร วงศ์ชัย รหัสนักศึกษา 63070224\n",
    "\n",
    "ธนภัทร ธีรรัตตัญญู รหัสนักศึกษา 63070227\n",
    "\n",
    "> **README**:\n",
    "> - 'Run all' is not recommended. \n",
    "> - Section 1 must be run before any other section.\n",
    "> - Read and follow instruction of each section carefully if it is provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Init Project\n",
    "\n",
    "> **Instruction**: Set `ROOT_PATH` before running this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Set Root Path\n",
    "\n",
    "* If you initialize this project for first time, run code cell R1\n",
    "* Otherwise, set your own root path in code cell R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Code Cell R1 ###\n",
    "\n",
    "# ROOT_PATH = os.getcwd() # Get current working directory\n",
    "\n",
    "# # Create /data directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/article_metadata directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/article_metadata')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/datastore directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/datastore')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/datastore/article_contents_by_month directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/datastore/article_contents_by_month')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/datastore/article_titles_by_month directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/datastore/article_titles_by_month')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/target directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/target')\n",
    "# os.mkdir(dir)\n",
    "\n",
    "# # Create /data/target/article_categories_by_month directory\n",
    "# dir = os.path.join(ROOT_PATH, 'data/target/article_categories_by_month')\n",
    "# os.mkdir(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell R2 ###\n",
    "\n",
    "# Set your own root path here\n",
    "ROOT_PATH = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Scraping from Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and packages used in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 กำหนดค่าคงที่และสร้างฟังก์ชันที่ใช้งานบ่อย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 กำหนดค่าคงที่ BASE_URL ของ News Article Archive ตามเซลล์โค้ดที่ 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.1.1 ###\n",
    "\n",
    "BASE_URL = 'http://www.it.kmitl.ac.th/~teerapong/news_archive/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 สร้างฟังก์ชันสำหรับส่ง GET request ไปยัง URL ที่ต้องการ พร้อมตรวจสอบว่าการส่งนั้นสำเร็จหรือไม่ (มี status เป็น 200) ถ้าไม่สำเร็จ ให้ทำการ raise Exception ตามเซลล์โค้ดที่ 2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.1.2 ###\n",
    "\n",
    "def get_request(url: str, **kwargs) -> requests.models.Response:\n",
    "    \"\"\"\n",
    "    Call GET request using requests package \n",
    "    then return response if it is successful (status 200)\n",
    "    otherwise throw an exception.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "      URL to request\n",
    "    **kwargs\n",
    "      Other parameters for requests.get\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    requests.models.Response\n",
    "      Response of the request\n",
    "    \"\"\"\n",
    "    res = requests.get(url, **kwargs)\n",
    "\n",
    "    # If the request is not successful, throw an exception.\n",
    "    if (res.status_code != 200):\n",
    "        print(res.text)\n",
    "        err = Exception('The request is not successful. ' +\n",
    "                        f'Its status code is {res.status_code}. ' +\n",
    "                        f'The URL of request is {res.url}')\n",
    "        raise err\n",
    "    else:\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 เก็บ URL ของหน้ารวมบทความข่าวแต่ละเดือน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 request หน้า index ของ News Article Archive และแปลงด้วย BeautifulSoup ตามเซลล์โค้ดที่ 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.2.1 ###\n",
    "\n",
    "index_url = BASE_URL + 'index.html'\n",
    "res = get_request(index_url)\n",
    "index_page = BeautifulSoup(res.content, 'lxml')  # Parse the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2 เนื่องจากในหน้า index จะมีรายการของเดือนที่มีทั้งหมดอยู่ใน `<li>` ซึ่งเชื่อมไปยังหน้ารวมบทความข่าวของเดือนนั้น ๆ จึงทำการดึง `<li>` tag ตามเซลล์โค้ดที่ 2.2.2.1 จากนั้นทำการดึงค่าของ `href` ของ `<a>` ที่อยู่ในแต่ละ `<li>` tag ที่ได้มา ตามเซลล์โค้ดที่ 2.2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>Articles — <a href=\"month-jan-2017.html\">January</a> [118]</li>,\n",
       " <li>Articles — <a href=\"month-feb-2017.html\">February</a> [124]</li>,\n",
       " <li>Articles — <a href=\"month-mar-2017.html\">March</a> [116]</li>,\n",
       " <li>Articles — <a href=\"month-apr-2017.html\">April</a> [118]</li>,\n",
       " <li>Articles — <a href=\"month-may-2017.html\">May</a> [115]</li>,\n",
       " <li>Articles — <a href=\"month-jun-2017.html\">June</a> [115]</li>,\n",
       " <li>Articles — <a href=\"month-jul-2017.html\">July</a> [122]</li>,\n",
       " <li>Articles — <a href=\"month-aug-2017.html\">August</a> [116]</li>,\n",
       " <li>Articles — <a href=\"month-sep-2017.html\">September</a> [113]</li>,\n",
       " <li>Articles — <a href=\"month-oct-2017.html\">October</a> [124]</li>,\n",
       " <li>Articles — <a href=\"month-nov-2017.html\">November</a> [122]</li>,\n",
       " <li>Articles — <a href=\"month-dec-2017.html\">December</a> [115]</li>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 2.2.2.1 ###\n",
    "\n",
    "tags = index_page.select('li')\n",
    "tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month-jan-2017.html\n",
      "month-feb-2017.html\n",
      "month-mar-2017.html\n",
      "month-apr-2017.html\n",
      "month-may-2017.html\n",
      "month-jun-2017.html\n",
      "month-jul-2017.html\n",
      "month-aug-2017.html\n",
      "month-sep-2017.html\n",
      "month-oct-2017.html\n",
      "month-nov-2017.html\n",
      "month-dec-2017.html\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.2.2.2 ###\n",
    "\n",
    "month_links = list()\n",
    "for tag in tags:\n",
    "    link = tag.find('a')['href']\n",
    "    month_links.append(link)\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 เก็บข้อมูล metadata ของบทความข่าวในแต่ละเดือน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1 สร้างฟังก์ชันสำหรับใช้สกัดเอาข้อมูลชื่อเรื่อง หมวดหมู่ และลิงก์ ของแต่ละบทความข่าวในหน้ารวมบทความในเดือนหนึ่ง โดยจะเก็บเฉพาะบทความที่ยังเข้าถึงได้ ตามเซลล์โค้ดที่ 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.3.1 ###\n",
    "\n",
    "def scrape_month_page(month_url: str):\n",
    "    \"\"\"\n",
    "    Scrape title, category and link of available news articles from month page.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    month_url : str\n",
    "      URL of month page\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    DataFrame\n",
    "      DataFrame containing title, category and link of news articles\n",
    "    \"\"\"\n",
    "\n",
    "    res = get_request(month_url)\n",
    "    month_page = BeautifulSoup(res.content, 'lxml')  # Parse the response\n",
    "\n",
    "    # Each article's title, category, and link are in tr tag,\n",
    "    # so select all tr tag.\n",
    "    articles = month_page.select('tbody>tr')\n",
    "\n",
    "    article_titles = list()\n",
    "    article_categories = list()\n",
    "    article_links = list()\n",
    "\n",
    "    for article in articles:\n",
    "\n",
    "        # Category is in td tag with category class.\n",
    "        category = article.select_one('td.category').string.strip()\n",
    "\n",
    "        # Skip article if it is unavailable.\n",
    "        if (category != 'N/A'):\n",
    "            # Title is in a tag inside td tag with title class.\n",
    "            title = article.select_one('td.title>a').string\n",
    "            # Link to article page is href attribute of\n",
    "            # a tag inside td tag with title class.\n",
    "            link = article.select_one('td.title>a')['href']\n",
    "\n",
    "            article_titles.append(title)\n",
    "            article_categories.append(category)\n",
    "            article_links.append(link)\n",
    "\n",
    "    articles_df = pd.DataFrame({'title': article_titles,\n",
    "                                'category': article_categories,\n",
    "                                'link': article_links})\n",
    "    return articles_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2 เก็บข้อมูล metadata ของบทความ (หัวข้อ หมวดหมู่ และลิงก์) ในแต่ละเดือน โดยใช้ฟังก์ชันจากข้อ 2.3.1 และบันทึกเป็นไฟล์ csv แยกแต่ละเดือน ตามเซลล์โค้ดที่ 2.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jan-2017.html\n",
      "Scraped 118 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_01.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-feb-2017.html\n",
      "Scraped 122 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_02.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-mar-2017.html\n",
      "Scraped 116 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_03.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-apr-2017.html\n",
      "Scraped 117 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_04.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-may-2017.html\n",
      "Scraped 114 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_05.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jun-2017.html\n",
      "Scraped 114 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_06.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-jul-2017.html\n",
      "Scraped 122 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_07.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-aug-2017.html\n",
      "Scraped 116 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_08.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-sep-2017.html\n",
      "Scraped 112 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_09.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-oct-2017.html\n",
      "Scraped 122 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_10.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-nov-2017.html\n",
      "Scraped 121 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_11.csv\n",
      "----------\n",
      "Scraping http://www.it.kmitl.ac.th/~teerapong/news_archive/month-dec-2017.html\n",
      "Scraped 114 article metadata\n",
      "Saved to ROOT_PATH/data/article_metadata/article_metadata_2017_12.csv\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.3.2 ###\n",
    "\n",
    "month_abbr_to_number = {\n",
    "    'jan': '01',\n",
    "    'feb': '02',\n",
    "    'mar': '03',\n",
    "    'apr': '04',\n",
    "    'may': '05',\n",
    "    'jun': '06',\n",
    "    'jul': '07',\n",
    "    'aug': '08',\n",
    "    'sep': '09',\n",
    "    'oct': '10',\n",
    "    'nov': '11',\n",
    "    'dec': '12'\n",
    "}\n",
    "\n",
    "for month_link in month_links:\n",
    "\n",
    "    month_url = BASE_URL + month_link\n",
    "    print(f'Scraping {month_url}')\n",
    "    articles_df = scrape_month_page(month_url)\n",
    "    print(f'Scraped {articles_df.shape[0]} article metadata')\n",
    "\n",
    "    month = month_link[6:9]  # Get month abbriviation from month_link\n",
    "    month = month_abbr_to_number[month]  # Convert to month number\n",
    "    year = month_link[10:14]  # Get year from month_link\n",
    "    file_name = f'article_metadata_{year}_{month}.csv'\n",
    "    file_path = f'{ROOT_PATH}/data/article_metadata/{file_name}'\n",
    "    articles_df.to_csv(file_path, index=False)\n",
    "    print(f'Saved to ROOT_PATH/data/article_metadata/{file_name}')\n",
    "    print('-'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 เก็บข้อมูลเนื้อความจากหน้าบทความข่าว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1 สร้างฟังก์ชันสำหรับใช้สกัดเอาข้อมูลเนื้อความจากหน้าบทความข่าว ตามเซลล์โค้ดที่ 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.4.1 ###\n",
    "\n",
    "def scrape_article_page(article_url: str):\n",
    "    \"\"\"\n",
    "    Scrape article content from news article page with a given URL.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    article_url : str\n",
    "      URL of article page\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "      Article content\n",
    "    \"\"\"\n",
    "\n",
    "    res = get_request(article_url)\n",
    "    article_page = BeautifulSoup(res.content, 'lxml')  # Parse the response\n",
    "\n",
    "    # Get content of article, which is in p tags without 'notice' class\n",
    "    # in div.main\n",
    "    p_tags = article_page.select('div.main>p:not(.notice)')\n",
    "\n",
    "    # Every article repeats its title in content section.\n",
    "    # Due to inconsistent formating style, some articles repeat in b tag\n",
    "    # while some repeat in p tag. In the later case, remove first item of\n",
    "    # selected p_tags.\n",
    "    b_tags = article_page.select('div.main>b')\n",
    "    # If there is no b tag in content section, remove first item of\n",
    "    # selected p_tags\n",
    "    if (len(b_tags) == 0):\n",
    "        p_tags.pop(0)\n",
    "\n",
    "    article_content = ''\n",
    "    # Concatenate all paragraphs\n",
    "    for p in p_tags:\n",
    "        article_content += p.text + ' '\n",
    "\n",
    "    # Replace double space with single space and\n",
    "    # remove leading and trailing whitespace\n",
    "    article_content = article_content.replace('  ', ' ').strip()\n",
    "\n",
    "    return article_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.2 อ่านไฟล์ metadata ของบทความในแต่ละเดือน จากนั้นใช้ลิงก์ที่อยู่ใน metadata ไปทำการเก็บข้อมูลเนื้อความของบทความแต่ละบทความ โดยใช้ฟังก์ชันจากข้อ 2.4.1 และบันทึกเป็นไฟล์ txt แยกตามเดือน โดยที่เก็บเนื้อความของ 1 บทความต่อบรรทัด ตามเซลล์โค้ดที่ 2.4.2.1 - 2.4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['article_metadata_2017_01.csv',\n",
       " 'article_metadata_2017_02.csv',\n",
       " 'article_metadata_2017_03.csv',\n",
       " 'article_metadata_2017_04.csv',\n",
       " 'article_metadata_2017_05.csv',\n",
       " 'article_metadata_2017_06.csv',\n",
       " 'article_metadata_2017_07.csv',\n",
       " 'article_metadata_2017_08.csv',\n",
       " 'article_metadata_2017_09.csv',\n",
       " 'article_metadata_2017_10.csv',\n",
       " 'article_metadata_2017_11.csv',\n",
       " 'article_metadata_2017_12.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 2.4.2.1 ###\n",
    "\n",
    "article_metadata_month_files = os.listdir(f'{ROOT_PATH}/data/article_metadata')\n",
    "article_metadata_month_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 118 articles from article_metadata_2017_01.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_01.txt\n",
      "----------\n",
      "Scraping 122 articles from article_metadata_2017_02.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_02.txt\n",
      "----------\n",
      "Scraping 116 articles from article_metadata_2017_03.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_03.txt\n",
      "----------\n",
      "Scraping 117 articles from article_metadata_2017_04.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_04.txt\n",
      "----------\n",
      "Scraping 114 articles from article_metadata_2017_05.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_05.txt\n",
      "----------\n",
      "Scraping 114 articles from article_metadata_2017_06.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_06.txt\n",
      "----------\n",
      "Scraping 122 articles from article_metadata_2017_07.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_07.txt\n",
      "----------\n",
      "Scraping 116 articles from article_metadata_2017_08.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_08.txt\n",
      "----------\n",
      "Scraping 112 articles from article_metadata_2017_09.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_09.txt\n",
      "----------\n",
      "Scraping 122 articles from article_metadata_2017_10.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_10.txt\n",
      "----------\n",
      "Scraping 121 articles from article_metadata_2017_11.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_11.txt\n",
      "----------\n",
      "Scraping 114 articles from article_metadata_2017_12.csv\n",
      "Saved to ROOT_PATH/data/datastore/article_contents_by_month/article_contents_2017_12.txt\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.4.2.2 ###\n",
    "\n",
    "count = 0  # Request count\n",
    "\n",
    "# article_metadata_month_files is a list of metadata file names\n",
    "# from code cell 2.4.2.1\n",
    "for article_metadata_month in article_metadata_month_files:\n",
    "\n",
    "    articles_df = pd.read_csv(\n",
    "        f'{ROOT_PATH}/data/article_metadata/{article_metadata_month}')\n",
    "    print(\n",
    "        f'Scraping {articles_df.shape[0]} articles from {article_metadata_month}')\n",
    "    article_contents = ''\n",
    "\n",
    "    # Scrape content of each article\n",
    "    for _, article in articles_df.iterrows():\n",
    "        article_link = article['link']\n",
    "        article_url = BASE_URL + article_link\n",
    "        article_content = scrape_article_page(article_url)\n",
    "        article_contents += article_content + '\\n'\n",
    "\n",
    "        # Delay for 1 sec after 25 consecutive requests\n",
    "        count += 1\n",
    "        if (count % 25 == 0):\n",
    "            time.sleep(1)\n",
    "\n",
    "    article_contents = article_contents.rstrip('\\n')  # Remove last empty line\n",
    "\n",
    "    # Save contents in a file\n",
    "    year_month = article_metadata_month[17:24]  # Get year and month\n",
    "    file_name = f'article_contents_{year_month}.txt'\n",
    "    file_path = f'{ROOT_PATH}/data/datastore/article_contents_by_month/{file_name}'\n",
    "    f = open(file_path, mode='w', encoding='utf-8')  # Create a file\n",
    "    f.write(article_contents)  # Write a file\n",
    "    f.close()\n",
    "\n",
    "    print(\n",
    "        f'Saved to ROOT_PATH/data/datastore/article_contents_by_month/{file_name}')\n",
    "    print('-'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 จัดเก็บข้อมูลหัวข้อและหมวดหมู่ของบทความแยกจาก metadata ของบทความ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 อ่านไฟล์ metadata ของบทความในแต่ละเดือน จากนั้นดึงข้อมูลหัวข้อของบทความและบันทึกเป็นไฟล์ txt แยกตามเดือน โดยที่เก็บหัวข้อของ 1 บทความต่อบรรทัด และดึงข้อมูลหมวดหมู่ของบทความและบันทึกเป็นไฟล์ txt แยกตามเดือน โดยที่เก็บหมวดหมู่ของ 1 บทความต่อบรรทัด ตามเซลล์โค้ดที่ 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved titles and categories of 118 articles from article_metadata_2017_01.csv\n",
      "Saved titles and categories of 122 articles from article_metadata_2017_02.csv\n",
      "Saved titles and categories of 116 articles from article_metadata_2017_03.csv\n",
      "Saved titles and categories of 117 articles from article_metadata_2017_04.csv\n",
      "Saved titles and categories of 114 articles from article_metadata_2017_05.csv\n",
      "Saved titles and categories of 114 articles from article_metadata_2017_06.csv\n",
      "Saved titles and categories of 122 articles from article_metadata_2017_07.csv\n",
      "Saved titles and categories of 116 articles from article_metadata_2017_08.csv\n",
      "Saved titles and categories of 112 articles from article_metadata_2017_09.csv\n",
      "Saved titles and categories of 122 articles from article_metadata_2017_10.csv\n",
      "Saved titles and categories of 121 articles from article_metadata_2017_11.csv\n",
      "Saved titles and categories of 114 articles from article_metadata_2017_12.csv\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.5 ###\n",
    "\n",
    "# article_metadata_month_files is a list of metadata file names\n",
    "# from code cell 2.4.2.1\n",
    "for article_metadata_month in article_metadata_month_files:\n",
    "\n",
    "    articles_df = pd.read_csv(\n",
    "        f'{ROOT_PATH}/data/article_metadata/{article_metadata_month}')\n",
    "\n",
    "    # Get array of article titles then join with new line\n",
    "    article_titles = '\\n'.join(articles_df['title'].to_numpy())\n",
    "\n",
    "    # Get array of article categories then join with new line\n",
    "    article_categories = '\\n'.join(articles_df['category'].to_numpy())\n",
    "\n",
    "    year_month = article_metadata_month[17:24]  # Get year and month\n",
    "\n",
    "    # Save article titles in a file\n",
    "    file_name = f'article_titles_{year_month}.txt'\n",
    "    file_path = f'{ROOT_PATH}/data/datastore/article_titles_by_month/{file_name}'\n",
    "    with open(file_path, mode='w', encoding='utf-8') as file:\n",
    "        file.write(article_titles)\n",
    "\n",
    "    # Save article categories in a file\n",
    "    file_name = f'article_categories_{year_month}.txt'\n",
    "    file_path = f'{ROOT_PATH}/data/target/article_categories_by_month/{file_name}'\n",
    "    with open(file_path, mode='w', encoding='utf-8') as file:\n",
    "        file.write(article_categories)\n",
    "\n",
    "    print(f'Saved titles and categories of {articles_df.shape[0]} ' +\n",
    "          f'articles from {article_metadata_month}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 รวมไฟล์ข้อมูลหัวข้อ เนื้อความ และหมวดหมู่ของบทความในทุกเดือน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1 สร้างฟังก์ชันสำหรับรวมไฟล์ ตามเซลล์โค้ดที่ 2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 2.6.1 ###\n",
    "\n",
    "def merge_text_files(file_paths: list, out_file_path: str):\n",
    "    \"\"\"\n",
    "    Merge text files in the same order as a given file path list\n",
    "    then write an out file with a given path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_paths : list\n",
    "      List of text file paths\n",
    "    out_file_path : str\n",
    "      File path to write a merged text file\n",
    "    \"\"\"\n",
    "\n",
    "    data = ''\n",
    "\n",
    "    for i in range(len(file_paths)):\n",
    "        with open(file_paths[i], mode='r', encoding='utf-8') as file:\n",
    "            data += file.read()  # Append content of current text file to data\n",
    "\n",
    "        # Add new line to data if it is not the last text file\n",
    "        if (i < len(file_paths) - 1):\n",
    "            data += '\\n'\n",
    "\n",
    "    # Write a merged text file\n",
    "    with open(out_file_path, mode='w', encoding='utf-8') as file:\n",
    "        file.write(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2 รวมไฟล์ข้อมูลหัวข้อของบทความ โดยใช้ฟังก์ชันจากข้อ 2.6.1 ตามเซลล์โค้ดที่ 2.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed merging article title files\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.6.2 ###\n",
    "\n",
    "# Get a list of file names in article_titles_by_month directory.\n",
    "article_titles_by_month_dir = f'{ROOT_PATH}/data/datastore/article_titles_by_month'\n",
    "article_titles_file_names = os.listdir(article_titles_by_month_dir)\n",
    "\n",
    "# Add directory path to file name.\n",
    "article_titles_file_paths = [\n",
    "    article_titles_by_month_dir + '/' + file_name\n",
    "    for file_name in article_titles_file_names\n",
    "]\n",
    "\n",
    "article_titles_all_file_path = f'{ROOT_PATH}/data/datastore/article_titles_all.txt'\n",
    "\n",
    "merge_text_files(article_titles_file_paths, article_titles_all_file_path)\n",
    "print('Completed merging article title files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.3 รวมไฟล์ข้อมูลเนื้อความของบทความ โดยใช้ฟังก์ชันจากข้อ 2.6.1 ตามเซลล์โค้ดที่ 2.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed merging article content files\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.6.3 ###\n",
    "\n",
    "# Get a list of file names in article_contents_by_month directory.\n",
    "article_contents_by_month_dir = f'{ROOT_PATH}/data/datastore/article_contents_by_month'\n",
    "article_contents_file_names = os.listdir(article_contents_by_month_dir)\n",
    "\n",
    "# Add directory path to file name.\n",
    "article_contents_file_paths = [\n",
    "    article_contents_by_month_dir + '/' + file_name\n",
    "    for file_name in article_contents_file_names\n",
    "]\n",
    "\n",
    "article_contents_all_file_path = f'{ROOT_PATH}/data/datastore/article_contents_all.txt'\n",
    "\n",
    "merge_text_files(article_contents_file_paths, article_contents_all_file_path)\n",
    "print('Completed merging article content files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.4 รวมไฟล์ข้อมูลหมวดหมู่ของบทความ โดยใช้ฟังก์ชันจากข้อ 2.6.1 ตามเซลล์โค้ดที่ 2.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed merging article catagory files\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.6.4 ###\n",
    "\n",
    "# Get a list of file names in article_categories_by_month directory.\n",
    "article_categories_by_month_dir = f'{ROOT_PATH}/data/target/article_categories_by_month'\n",
    "article_categories_file_names = os.listdir(article_categories_by_month_dir)\n",
    "\n",
    "# Add directory path to file name.\n",
    "article_categories_file_paths = [\n",
    "    article_categories_by_month_dir + '/' + file_name\n",
    "    for file_name in article_categories_file_names\n",
    "]\n",
    "\n",
    "article_categories_all_file_path = f'{ROOT_PATH}/data/target/article_categories_all.txt'\n",
    "\n",
    "merge_text_files(article_categories_file_paths,\n",
    "                 article_categories_all_file_path)\n",
    "print('Completed merging article catagory files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 รวมข้อมูลหัวข้อและเนื้อความของบทความเข้าด้วยกัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 อ่านไฟล์ข้อมูลหัวข้อของบทความและไฟล์ข้อมูลเนื้อความของบทความ แล้วนำหัวข้อต่อกับเนื้อความของแต่ละบทความโดยคั่นด้วยเว้นวรรค และบันทึกเป็นไฟล์ txt โดยที่เก็บหัวข้อที่ต่อด้วยเนื้อความของ 1 บทความต่อบรรทัด ตามเซลล์โค้ดที่ 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed merging article_titles_all.txt and article_contents_all.txt\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 2.7 ###\n",
    "\n",
    "# Define article title file path and article content file path to read\n",
    "titles_file_path = f'{ROOT_PATH}/data/datastore/article_titles_all.txt'\n",
    "contents_file_path = f'{ROOT_PATH}/data/datastore/article_contents_all.txt'\n",
    "\n",
    "# Define file path to write\n",
    "out_file_name = 'article_titles_plus_contents_all.txt'\n",
    "out_file_path = f'{ROOT_PATH}/data/datastore/{out_file_name}'\n",
    "\n",
    "# Read article title file and article content file\n",
    "# and merge them line by line into an out file.\n",
    "with open(titles_file_path, mode='r', encoding='utf-8') as titles_file:\n",
    "    with open(contents_file_path, mode='r', encoding='utf-8') as contents_file:\n",
    "        with open(out_file_path, mode='w', encoding='utf-8') as out_file:\n",
    "            titles = titles_file.readlines()\n",
    "            contents = contents_file.readlines()\n",
    "\n",
    "            titles_plus_contents = ''\n",
    "\n",
    "            # Merge titles and contents line by line\n",
    "            for title, content in zip(titles, contents):\n",
    "                title_plus_content = title.rstrip(\n",
    "                    '\\n') + ' ' + content.rstrip('\\n')\n",
    "                titles_plus_contents += title_plus_content + '\\n'\n",
    "\n",
    "            # Remove last empty line\n",
    "            titles_plus_contents = titles_plus_contents.rstrip('\\n')\n",
    "\n",
    "            # Write title plus content file\n",
    "            out_file.write(titles_plus_contents)\n",
    "\n",
    "print('Completed merging article_titles_all.txt and article_contents_all.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-Class Classification\n",
    "\n",
    "> **Instruction**: Scraped data from section 2 must exist in `ROOT_PATH/data` before running this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and packages used in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Preprocessing ###\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer as SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification ###\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 อ่านข้อมูลจากการทำ Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1 อ่านข้อมูลเนื้อความของบทความ ตามเซลล์โค้ดที่ 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.1.1 ###\n",
    "\n",
    "with open(f'{ROOT_PATH}/data/datastore/article_contents_all.txt',\n",
    "          mode='r', encoding='utf-8') as file:\n",
    "    contents = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2 อ่านข้อมูลหัวข้อต่อกับเนื้อความของบทความ ตามเซลล์โค้ดที่ 3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.1.2 ###\n",
    "\n",
    "with open(f'{ROOT_PATH}/data/datastore/article_titles_plus_contents_all.txt',\n",
    "          mode='r', encoding='utf-8') as file:\n",
    "    contents_with_title = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.3 อ่านข้อมูลหมวดหมู่ของบทความ ตามเซลล์โค้ดที่ 3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.1.3 ###\n",
    "\n",
    "with open(f'{ROOT_PATH}/data/target/article_categories_all.txt',\n",
    "          mode='r', encoding='utf-8') as file:\n",
    "    targets = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Basic Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1.1 กำหนด STOPS_WORDS โดยรวมเซ็ทคำ stop word ของทั้ง NLTK และ Sklearn เข้าด้วยกัน ตามเซลล์โค้ดที่ 3.2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.1.1 ###\n",
    "\n",
    "NLTK_STOP_WORDS = set(stopwords.words('english'))\n",
    "SKLEARN_STOP_WORDS = ENGLISH_STOP_WORDS\n",
    "\n",
    "# Merge stop words from ntlk and sklearn\n",
    "STOP_WORDS = NLTK_STOP_WORDS.union(SKLEARN_STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1.2 สร้าง tokenizer โดยนำเอา word tokenizer จาก NLTK มาเพิ่มการทำ normalizing และการกรองเอาคำ stop words ตัวเลข และเครื่องหมายวรรคตอน (punctuation mark) ออก ตามเซลล์โค้ดที่ 3.2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.1.2 ###\n",
    "\n",
    "def word_tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize given text using NLTK's word tokenizer\n",
    "    with normalizing (lowercasing string) and filtering \n",
    "    stop words, numbers and punctuation marks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    tokens_to_return = list()\n",
    "    for token in tokens:\n",
    "        token = token.strip(\"'\")\n",
    "\n",
    "        # Filter number\n",
    "        if (re.match(r\"^[\\d.]+$\", token)):\n",
    "            continue\n",
    "        # Filter punctuation mark and stop word\n",
    "        elif (re.match(r\"[\\w'-]+\", token) and (token not in ['-', \"'\"])\n",
    "              and (token not in STOP_WORDS)):\n",
    "            tokens_to_return.append(token)\n",
    "\n",
    "    return tokens_to_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1.3 นำ tokenizer ที่ได้มาทดสอบ ตามเซลล์โค้ดที่ 3.2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "It's 21-century education. \n",
      "They are Mr. and Mrs. Brown. \n",
      "While this seems like a cliché, it is true. \n",
      "6.80 pounds :; or £6.80\n",
      "— em dash – en dash - hyphen\n",
      "----------\n",
      "NLTK's word tokenizer:\n",
      "['It', \"'s\", '21-century', 'education', '.', 'They', 'are', 'Mr.', 'and', 'Mrs.', 'Brown', '.', 'While', 'this', 'seems', 'like', 'a', 'cliché', ',', 'it', 'is', 'true', '.', '6.80', 'pounds', ':', ';', 'or', '£6.80', '—', 'em', 'dash', '–', 'en', 'dash', '-', 'hyphen']\n",
      "----------\n",
      "Custom word tokenizer:\n",
      "['21-century', 'education', 'mr.', 'mrs.', 'brown', 'like', 'cliché', 'true', 'pounds', 'em', 'dash', 'en', 'dash', 'hyphen']\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.2.1.3 ###\n",
    "\n",
    "test_text = \"\"\"It's 21-century education. \n",
    "They are Mr. and Mrs. Brown. \n",
    "While this seems like a cliché, it is true. \n",
    "6.80 pounds :; or £6.80\n",
    "— em dash – en dash - hyphen\"\"\"\n",
    "print(\"Original text:\")\n",
    "print(test_text)\n",
    "print('-'*10)\n",
    "print(\"NLTK's word tokenizer:\")\n",
    "print(word_tokenize(test_text))\n",
    "print('-'*10)\n",
    "print(\"Custom word tokenizer:\")\n",
    "print(word_tokenizer(test_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Tokenizer with Stemmer or Lemmatizer\n",
    "\n",
    "นำ tokenizer ที่สร้างขึ้นจากข้อ 3.2.1 มาเพิ่ม stemmer หรือ lemmatizer เข้าไป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2.1 สร้าง tokenizer โดยเพิ่ม Porter stemmer ตามเซลล์โค้ดที่ 3.2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.2.1 ###\n",
    "\n",
    "def porter_stem_tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize given text using custom word tokenizer\n",
    "    (based on NLTK word tokenizer) with Porter stemmer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenizer(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = list()\n",
    "    for token in tokens:\n",
    "        stems.append(stemmer.stem(token))\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2.2 สร้าง tokenizer โดยเพิ่ม Porter stemmer ตามเซลล์โค้ดที่ 3.2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.2.2 ###\n",
    "\n",
    "def snowball_stem_tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize given text using custom word tokenizer\n",
    "    (based on NLTK word tokenizer) with Snowball stemmer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenizer(text)\n",
    "    stemmer = SnowballStemmer()\n",
    "    stems = list()\n",
    "    for token in tokens:\n",
    "        stems.append(stemmer.stem(token))\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2.3 สร้าง tokenizer โดยเพิ่ม Lancaster stemmer ตามเซลล์โค้ดที่ 3.2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.2.3 ###\n",
    "\n",
    "def lancaster_stem_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenize given text using custom word tokenizer\n",
    "    (based on NLTK word tokenizer) with Lancaster stemmer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenizer(text)\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = list()\n",
    "    for token in tokens:\n",
    "        stems.append(stemmer.stem(token))\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2.4 สร้าง tokenizer โดยเพิ่ม Wordnet lemmatizer ตามเซลล์โค้ดที่ 3.2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.2.4 ###\n",
    "\n",
    "def wordnet_lemma_tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize given text using custom word tokenizer\n",
    "    (based on NLTK word tokenizer) with Wordnet lemmatizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenizer(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = list()\n",
    "    for token in tokens:\n",
    "        lemmas.append(lemmatizer.lemmatize(token))\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2.5 สร้าง tokenizer โดยเพิ่ม Wordnet lemmatizer with POS ตามเซลล์โค้ดที่ 3.2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.2.5 ###\n",
    "\n",
    "def convert_tag(tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert part-of-speech tag to tag compatible \n",
    "    with WordNet lemmatizer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tag : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "      Part-of-speech tag compatible with WordNet lemmatizer; \n",
    "      \"n\" for noun, \"v\" for verb, \"a\" for adjective and \"r\" for adverb\n",
    "    \"\"\"\n",
    "    if tag[0] == 'V':\n",
    "        return 'v'\n",
    "    elif tag[0] == 'J':\n",
    "        return 'a'\n",
    "    elif tag[0] == 'R':\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "def wordnet_lemma_pos_tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize given text using custom word tokenizer\n",
    "    (based on NLTK word tokenizer) with Wordnet lemmatizer\n",
    "    given word's part-of-speech\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "      Text to be tokenized\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "      List of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenizer(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = list()\n",
    "    tokens_with_pos_tag = pos_tag(tokens)\n",
    "    for token in tokens_with_pos_tag:\n",
    "        word = token[0]\n",
    "        pos = convert_tag(token[1])\n",
    "        lemmas.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Vectorizing Raw Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3.1 กำหนด list ของ tokenizer แบบต่างๆ ที่ได้สร้างขึ้นจากข้อ 3.2.1 และ 3.2.2 ตามเซลล์โค้ดที่ 3.2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.2.3.1 ###\n",
    "\n",
    "tokenizers = [word_tokenizer, porter_stem_tokenizer,\n",
    "              snowball_stem_tokenizer, lancaster_stem_tokenizer,\n",
    "              wordnet_lemma_tokenizer, wordnet_lemma_pos_tokenizer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3.2 ทำการ tokenize ข้อความเนื้อความของบทความ (contents) ด้วย tokenizer แบบต่างๆ จากนั้นนำไปเข้า TFIDF vectorizer เพื่อทำการ term weighting โดยที่กำหนด min_df อยู่ที่ 0.1 ตามเซลล์โค้ดที่ 3.2.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing with word_tokenizer\n",
      "Vectorizing with porter_stem_tokenizer\n",
      "Vectorizing with snowball_stem_tokenizer\n",
      "Vectorizing with lancaster_stem_tokenizer\n",
      "Vectorizing with wordnet_lemma_tokenizer\n",
      "Vectorizing with wordnet_lemma_pos_tokenizer\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.2.3.2 ###\n",
    "\n",
    "contents_X = dict()\n",
    "\n",
    "for tokenizer in tokenizers:\n",
    "    print(f'Vectorizing with {tokenizer.__name__}')\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer, min_df=0.01)\n",
    "    term_weighted = vectorizer.fit_transform(contents)\n",
    "    contents_X[tokenizer.__name__] = term_weighted.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3.3 ทำการ tokenize ข้อความหัวข้อต่อกับเนื้อความของบทความ (contents_with_title) ด้วย tokenizer แบบต่างๆ จากนั้นนำไปเข้า TFIDF vectorizer เพื่อทำการ term weighting โดยที่กำหนด min_df อยู่ที่ 0.1 ตามเซลล์โค้ดที่ 3.2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing with word_tokenizer\n",
      "Vectorizing with porter_stem_tokenizer\n",
      "Vectorizing with snowball_stem_tokenizer\n",
      "Vectorizing with lancaster_stem_tokenizer\n",
      "Vectorizing with wordnet_lemma_tokenizer\n",
      "Vectorizing with wordnet_lemma_pos_tokenizer\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.2.3.2 ###\n",
    "\n",
    "contents_with_title_X = dict()\n",
    "\n",
    "for tokenizer in tokenizers:\n",
    "    print(f'Vectorizing with {tokenizer.__name__}')\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer, min_df=0.01)\n",
    "    term_weighted = vectorizer.fit_transform(contents_with_title)\n",
    "    contents_with_title_X[tokenizer.__name__] = term_weighted.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Classification 1\n",
    "\n",
    "นำข้อมูลเนื้อความของบทความ (contents_X) ที่เตรียมไว้จากข้อ 3.2.3.2 มาทำการทดลองกับโมเดล KNN, RandomForest และ LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 กำหนด model และช่วงของค่า parameter ที่ต้องการทำ tuning ตามเซลล์โค้ดที่ 3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.3.1 ###\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": list(range(3, 16, 2))}\n",
    "    },\n",
    "    {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            \"C\": list(np.arange(0.1, 1.1, 0.1))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": list(range(25, 201, 25)),\n",
    "            \"min_samples_split\": list(range(5, 26, 5)),\n",
    "            \"random_state\": [28]\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 ทำการ parameter tuning หา parameter ที่ให้ค่า accuracy ที่ดีที่สุดด้วย 5-fold cross validation (GridSearchCV) ของคู่ model กับข้อมูลที่ผ่านการเตรียมด้วย tokenizer แบบต่างๆ จากนั้นนำมาทดสอบกับ test set เพื่อประเมินประสิทธิภาพ model ตามเซลล์โค้ดที่ 3.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs tokenized by word_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9597, params {'n_neighbors': 15}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9799, params {'C': 0.4, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9703, params {'min_samples_split': 15, 'n_estimators': 125, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by porter_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9682, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9820, params {'C': 0.5, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9724, params {'min_samples_split': 10, 'n_estimators': 75, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by snowball_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9682, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9830, params {'C': 0.8, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9703, params {'min_samples_split': 10, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by lancaster_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9735, params {'n_neighbors': 13}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9799, params {'C': 0.6, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9767, params {'min_samples_split': 5, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9661, params {'n_neighbors': 15}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9798, params {'C': 0.6, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9724, params {'min_samples_split': 20, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_pos_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9692, params {'n_neighbors': 15}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9820, params {'C': 0.8, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9714, params {'min_samples_split': 5, 'n_estimators': 75, 'random_state': 28}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.3.2 ###\n",
    "\n",
    "results1 = {\n",
    "    \"model\": [],\n",
    "    \"tokenizer\": [],\n",
    "    \"best_tuning_params\": [],\n",
    "    \"best_tuning_acc\": [],\n",
    "    \"accuracy\":[],\n",
    "    \"f1_score\":[],\n",
    "}\n",
    "cm = []\n",
    "y = targets\n",
    "\n",
    "for tokenizer_name, X in contents_X.items():\n",
    "    print(f'Docs tokenized by {tokenizer_name}')\n",
    "\n",
    "    # Stratified train-test split with test size of 33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "        random_state=50, test_size=.33, stratify=y) \n",
    "\n",
    "    for model in models:\n",
    "        print(f\"- Tuning {type(model['model']).__name__}:\")\n",
    "\n",
    "        # Search for best set of parameters, using 5-fold cross validation\n",
    "        clf = GridSearchCV(model['model'], model['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "        result = clf.fit(X_train, y_train)\n",
    "        results1['model'].append(type(model['model']).__name__)\n",
    "        results1['tokenizer'].append(tokenizer_name)\n",
    "        results1['best_tuning_params'].append(result.best_params_)\n",
    "        results1['best_tuning_acc'].append(result.best_score_)\n",
    "        print(f'Best tuning: acc {result.best_score_:.4f}, params {result.best_params_}')\n",
    "\n",
    "        # Test model with best set of parameters from GridSearchCV\n",
    "        model = model['model']\n",
    "        model.set_params(**result.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm.append(confusion_matrix(y_test, y_pred, labels=clf.classes_))\n",
    "        results1['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results1['f1_score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3 แสดงผลลัพธ์จากข้อ 3.3.2 ตามเซลล์โค้ดที่ 3.3.3.1 - 3.3.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.971985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.971971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.969892</td>\n",
       "      <td>0.969963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.969892</td>\n",
       "      <td>0.969873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.969892</td>\n",
       "      <td>0.969745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                    tokenizer  accuracy  f1_score\n",
       "0   RandomForestClassifier     lancaster_stem_tokenizer  0.980645  0.980610\n",
       "1   RandomForestClassifier      snowball_stem_tokenizer  0.976344  0.976311\n",
       "2       LogisticRegression               word_tokenizer  0.976344  0.976298\n",
       "3   RandomForestClassifier  wordnet_lemma_pos_tokenizer  0.974194  0.974177\n",
       "4       LogisticRegression        porter_stem_tokenizer  0.974194  0.974128\n",
       "5     KNeighborsClassifier  wordnet_lemma_pos_tokenizer  0.974194  0.974238\n",
       "6   RandomForestClassifier               word_tokenizer  0.972043  0.972001\n",
       "7       LogisticRegression  wordnet_lemma_pos_tokenizer  0.972043  0.972033\n",
       "8       LogisticRegression      wordnet_lemma_tokenizer  0.972043  0.971985\n",
       "9       LogisticRegression      snowball_stem_tokenizer  0.972043  0.972033\n",
       "10      LogisticRegression     lancaster_stem_tokenizer  0.972043  0.971971\n",
       "11    KNeighborsClassifier      wordnet_lemma_tokenizer  0.969892  0.969963\n",
       "12    KNeighborsClassifier               word_tokenizer  0.969892  0.969873\n",
       "13  RandomForestClassifier        porter_stem_tokenizer  0.969892  0.969745\n",
       "14    KNeighborsClassifier      snowball_stem_tokenizer  0.965591  0.965658\n",
       "15  RandomForestClassifier      wordnet_lemma_tokenizer  0.965591  0.965461\n",
       "16    KNeighborsClassifier        porter_stem_tokenizer  0.965591  0.965658\n",
       "17    KNeighborsClassifier     lancaster_stem_tokenizer  0.965591  0.965674"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.3.3.1 ###\n",
    "\n",
    "result_df = pd.DataFrame(results1)\n",
    "\n",
    "result_df[['model','tokenizer','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy'], ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.3.3.1 การจำแนกข้อความเนื้อความของบทความ (contents) ที่ทำการ preprocess โดยใช้ lancaster_stem_tokenizer ด้วย RandomForestClassifier ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 98.0645% และ f1 score อยู่ที่ 0.980610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.971985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tokenizer                   model  accuracy  f1_score\n",
       "0     lancaster_stem_tokenizer  RandomForestClassifier  0.980645  0.980610\n",
       "1      snowball_stem_tokenizer  RandomForestClassifier  0.976344  0.976311\n",
       "2               word_tokenizer      LogisticRegression  0.976344  0.976298\n",
       "3  wordnet_lemma_pos_tokenizer  RandomForestClassifier  0.974194  0.974177\n",
       "4        porter_stem_tokenizer      LogisticRegression  0.974194  0.974128\n",
       "5      wordnet_lemma_tokenizer      LogisticRegression  0.972043  0.971985"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.3.3.2 ###\n",
    "\n",
    "result_df[['tokenizer','model','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy'], ascending=False) \\\n",
    "    .groupby('tokenizer') \\\n",
    "    .head(1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.3.3.2 พบว่าจำแนกข้อความเนื้อความของบทความ (contents) ที่ทำการ preprocess โดยใช้ lancaster_stem_tokenizer, snowball_stem_tokenizer, word_tokenizer, wordnet_lemma_pos_tokenizer, porter_stem_tokenizer, wordnet_lemma_tokenizer ได้ดีที่สุดตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c00df190a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score_idx= result_df[['model','tokenizer','accuracy','f1_score']] .sort_values(by=['accuracy'], ascending=False).head(1).index[0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm[best_score_idx],\n",
    "                                display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Classification 2\n",
    "\n",
    "นำข้อมูลหัวข้อต่อกับเนื้อความของบทความ (contents_with_title_X) ที่เตรียมไว้จากข้อ 3.2.3.3 มาทำการทดลองกับโมเดล KNN, RandomForest และ LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1 กำหนด model และช่วงของค่า parameter ที่ต้องการทำ tuning ตามเซลล์โค้ดที่ 3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.4.1 ###\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": list(range(3, 16, 2))}\n",
    "    },\n",
    "    {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            \"C\": list(np.arange(0.1, 1.1, 0.1))\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": list(range(25, 201, 25)),\n",
    "            \"min_samples_split\": list(range(2, 26, 5)),\n",
    "            \"random_state\": [28]\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.2 ทำการ parameter tuning หา parameter ที่ให้ค่า accuracy ที่ดีที่สุดด้วย 5-fold cross validation (GridSearchCV) ของคู่ model กับข้อมูลที่ผ่านการเตรียมด้วย tokenizer แบบต่างๆ จากนั้นนำมาทดสอบกับ test set เพื่อประเมินประสิทธิภาพ model ตามเซลล์โค้ดที่ 3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs tokenized by word_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9576, params {'n_neighbors': 15}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9788, params {'C': 0.5, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9746, params {'min_samples_split': 7, 'n_estimators': 200, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by porter_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9682, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9830, params {'C': 0.8, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9725, params {'min_samples_split': 2, 'n_estimators': 150, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by snowball_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9661, params {'n_neighbors': 11}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9830, params {'C': 0.8, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9714, params {'min_samples_split': 7, 'n_estimators': 125, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by lancaster_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9682, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9809, params {'C': 0.9, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9746, params {'min_samples_split': 17, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9618, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9820, params {'C': 1.0, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9682, params {'min_samples_split': 17, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_pos_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9671, params {'n_neighbors': 9}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9830, params {'C': 0.8, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9735, params {'min_samples_split': 2, 'n_estimators': 100, 'random_state': 28}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.4.2 ###\n",
    "\n",
    "results2 = {\n",
    "    \"model\": [],\n",
    "    \"tokenizer\": [],\n",
    "    \"best_tuning_params\": [],\n",
    "    \"best_tuning_acc\": [],\n",
    "    \"accuracy\":[],\n",
    "    \"f1_score\":[],\n",
    "}\n",
    "cm = []\n",
    "y = targets\n",
    "\n",
    "for tokenizer_name, X in contents_with_title_X.items():\n",
    "    print(f'Docs tokenized by {tokenizer_name}')\n",
    "\n",
    "    # Stratified train-test split with test size of 33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "        random_state=50, test_size=.33, stratify=y) \n",
    "\n",
    "    for model in models:\n",
    "        print(f\"- Tuning {type(model['model']).__name__}:\")\n",
    "\n",
    "        # Search for best set of parameters, using 5-fold cross validation\n",
    "        clf = GridSearchCV(model['model'], model['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "        result = clf.fit(X_train, y_train)\n",
    "        results2['model'].append(type(model['model']).__name__)\n",
    "        results2['tokenizer'].append(tokenizer_name)\n",
    "        results2['best_tuning_params'].append(result.best_params_)\n",
    "        results2['best_tuning_acc'].append(result.best_score_)\n",
    "        print(f'Best tuning: acc {result.best_score_:.4f}, params {result.best_params_}')\n",
    "\n",
    "        # Test model with best set of parameters from GridSearchCV\n",
    "        model = model['model']\n",
    "        model.set_params(**result.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm.append(confusion_matrix(y_test, y_pred, labels=clf.classes_))\n",
    "        results2['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results2['f1_score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.3 แสดงผลลัพธ์จากข้อ 3.4.2 ตามเซลล์โค้ดที่ 3.4.3.1 - 3.4.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.978457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.967645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.967617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.967761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.965567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.963441</td>\n",
       "      <td>0.963504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.961387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.959140</td>\n",
       "      <td>0.959131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                    tokenizer  accuracy  f1_score\n",
       "0   RandomForestClassifier     lancaster_stem_tokenizer  0.978495  0.978457\n",
       "1   RandomForestClassifier  wordnet_lemma_pos_tokenizer  0.976344  0.976329\n",
       "2       LogisticRegression     lancaster_stem_tokenizer  0.976344  0.976336\n",
       "3       LogisticRegression        porter_stem_tokenizer  0.974194  0.974194\n",
       "4   RandomForestClassifier      snowball_stem_tokenizer  0.974194  0.974167\n",
       "5       LogisticRegression               word_tokenizer  0.974194  0.974155\n",
       "6   RandomForestClassifier               word_tokenizer  0.972043  0.972001\n",
       "7       LogisticRegression  wordnet_lemma_pos_tokenizer  0.972043  0.972012\n",
       "8       LogisticRegression      snowball_stem_tokenizer  0.972043  0.972012\n",
       "9       LogisticRegression      wordnet_lemma_tokenizer  0.972043  0.972012\n",
       "10  RandomForestClassifier      wordnet_lemma_tokenizer  0.967742  0.967645\n",
       "11  RandomForestClassifier        porter_stem_tokenizer  0.967742  0.967617\n",
       "12    KNeighborsClassifier      wordnet_lemma_tokenizer  0.967742  0.967761\n",
       "13    KNeighborsClassifier  wordnet_lemma_pos_tokenizer  0.965591  0.965621\n",
       "14    KNeighborsClassifier               word_tokenizer  0.965591  0.965567\n",
       "15    KNeighborsClassifier      snowball_stem_tokenizer  0.963441  0.963504\n",
       "16    KNeighborsClassifier     lancaster_stem_tokenizer  0.961290  0.961387\n",
       "17    KNeighborsClassifier        porter_stem_tokenizer  0.959140  0.959131"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.4.3.1 ###\n",
    "\n",
    "result_df = pd.DataFrame(results2)\n",
    "\n",
    "result_df[['model','tokenizer','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy'], ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.4.3.1 การจำแนกข้อความหัวข้อต่อกับเนื้อความของบทความ (contents_with_title) ที่ทำการ preprocess โดยใช้ snowball_stem_tokenizer ด้วย RandomForestClassifier ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 97.6344% และ f1 score อยู่ที่ 0.976341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.978457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.976329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>0.972012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tokenizer                   model  accuracy  f1_score\n",
       "0     lancaster_stem_tokenizer  RandomForestClassifier  0.978495  0.978457\n",
       "1  wordnet_lemma_pos_tokenizer  RandomForestClassifier  0.976344  0.976329\n",
       "2        porter_stem_tokenizer      LogisticRegression  0.974194  0.974194\n",
       "3      snowball_stem_tokenizer  RandomForestClassifier  0.974194  0.974167\n",
       "4               word_tokenizer      LogisticRegression  0.974194  0.974155\n",
       "5      wordnet_lemma_tokenizer      LogisticRegression  0.972043  0.972012"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.4.3.2 ###\n",
    "\n",
    "result_df[['tokenizer','model','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy'], ascending=False) \\\n",
    "    .groupby('tokenizer') \\\n",
    "    .head(1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.4.3.2 พบว่าจำแนกข้อความหัวข้อต่อกับเนื้อความของบทความ (contents_with_title) ที่ทำการ preprocess โดยใช้ snowball_stem_tokenizer, lancaster_stem_tokenizer, porter_stem_tokenizer, word_tokenizer, wordnet_lemma_tokenizer, wordnet_lemma_pos_tokenizer ได้ดีที่สุดตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c00f8191f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score_idx= result_df[['model','tokenizer','accuracy','f1_score']] .sort_values(by=['accuracy'], ascending=False).head(1).index[0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm[best_score_idx],\n",
    "                                display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Try Transforming with LDA 1\n",
    "\n",
    "นำข้อมูลเนื้อความของบทความ (contents_X) มาทดลองลดมิติข้อมูลลงด้วย LDA และทำการจำแนกแบบเดียวกันกับข้อที่ 3.3 เพื่อดูว่าจะทำให้การจำแนกมีประสิทธิภาพดีขึ้นหรือไม่"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.1 ลดมิติข้อมูลเนื้อความของบทความ (contents_X) ด้วย LDA ให้เหลือ 2 features ตามเซลล์โค้ดที่ 3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data tokenized by word_tokenizer\n",
      "Transforming data tokenized by porter_stem_tokenizer\n",
      "Transforming data tokenized by snowball_stem_tokenizer\n",
      "Transforming data tokenized by lancaster_stem_tokenizer\n",
      "Transforming data tokenized by wordnet_lemma_tokenizer\n",
      "Transforming data tokenized by wordnet_lemma_pos_tokenizer\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.5.1 ###\n",
    "\n",
    "contents_X_lda = dict()\n",
    "\n",
    "for tokenizer_name, X in contents_X.items():\n",
    "  print(f'Transforming data tokenized by {tokenizer_name}')\n",
    "  lda = LDA(n_components=2)\n",
    "  contents_X_lda[tokenizer_name] = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.2 กำหนด model และช่วงของค่า parameter ที่ต้องการทำ tuning ตามเซลล์โค้ดที่ 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.5.2 ###\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": list(range(3, 16, 2))}\n",
    "    },\n",
    "    {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            \"C\": np.arange(0.1, 1.1, 0.1)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": list(range(25, 201, 25)),\n",
    "            \"min_samples_split\": list(range(5, 26, 5)),\n",
    "            \"random_state\": [28]\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.3 ทำการ parameter tuning หา parameter ที่ให้ค่า accuracy ที่ดีที่สุดด้วย 5-fold cross validation (GridSearchCV) ของคู่ model กับข้อมูลที่ผ่านการเตรียมด้วย tokenizer แบบต่างๆ จากนั้นนำมาทดสอบกับ test set เพื่อประเมินประสิทธิภาพ model ตามเซลล์โค้ดที่ 3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs tokenized by word_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 1.0000, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by porter_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 1.0000, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by snowball_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by lancaster_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 1.0000, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_pos_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.5.3 ###\n",
    "\n",
    "results3 = {\n",
    "    \"model\": [],\n",
    "    \"tokenizer\": [],\n",
    "    \"best_tuning_params\": [],\n",
    "    \"best_tuning_acc\": [],\n",
    "    \"accuracy\":[],\n",
    "    \"f1_score\":[],\n",
    "}\n",
    "\n",
    "y = targets\n",
    "cm = []\n",
    "for tokenizer_name, X in contents_X_lda.items():\n",
    "    print(f'Docs tokenized by {tokenizer_name}')\n",
    "\n",
    "    # Stratified train-test split with test size of 33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "        random_state=50, test_size=.33, stratify=y) \n",
    "\n",
    "    for model in models:\n",
    "        print(f\"- Tuning {type(model['model']).__name__}:\")\n",
    "\n",
    "        # Search for best set of parameters, using 5-fold cross validation\n",
    "        clf = GridSearchCV(model['model'], model['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "        result = clf.fit(X_train, y_train)\n",
    "        results3['model'].append(type(model['model']).__name__)\n",
    "        results3['tokenizer'].append(tokenizer_name)\n",
    "        results3['best_tuning_params'].append(result.best_params_)\n",
    "        results3['best_tuning_acc'].append(result.best_score_)\n",
    "        print(f'Best tuning: acc {result.best_score_:.4f}, params {result.best_params_}')\n",
    "\n",
    "        # Test model with best set of parameters from GridSearchCV\n",
    "        model = model['model']\n",
    "        model.set_params(**result.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm.append(confusion_matrix(y_test, y_pred, labels=clf.classes_))\n",
    "        results3['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results3['f1_score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.4 แสดงผลลัพธ์จากข้อ 3.5.3 ตามเซลล์โค้ดที่ 3.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.997850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.997850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.997850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                    tokenizer  accuracy  f1_score\n",
       "6     KNeighborsClassifier      snowball_stem_tokenizer  0.997849  0.997850\n",
       "9     KNeighborsClassifier     lancaster_stem_tokenizer  0.997849  0.997850\n",
       "15    KNeighborsClassifier  wordnet_lemma_pos_tokenizer  0.997849  0.997850\n",
       "1       LogisticRegression               word_tokenizer  0.995699  0.995704\n",
       "2   RandomForestClassifier               word_tokenizer  0.995699  0.995704\n",
       "4       LogisticRegression        porter_stem_tokenizer  0.995699  0.995704\n",
       "5   RandomForestClassifier        porter_stem_tokenizer  0.995699  0.995704\n",
       "7       LogisticRegression      snowball_stem_tokenizer  0.995699  0.995704\n",
       "8   RandomForestClassifier      snowball_stem_tokenizer  0.995699  0.995704\n",
       "10      LogisticRegression     lancaster_stem_tokenizer  0.995699  0.995704\n",
       "11  RandomForestClassifier     lancaster_stem_tokenizer  0.995699  0.995704\n",
       "13      LogisticRegression      wordnet_lemma_tokenizer  0.995699  0.995704\n",
       "14  RandomForestClassifier      wordnet_lemma_tokenizer  0.995699  0.995704\n",
       "16      LogisticRegression  wordnet_lemma_pos_tokenizer  0.995699  0.995704\n",
       "17  RandomForestClassifier  wordnet_lemma_pos_tokenizer  0.995699  0.995704\n",
       "0     KNeighborsClassifier               word_tokenizer  0.995699  0.995698\n",
       "3     KNeighborsClassifier        porter_stem_tokenizer  0.995699  0.995698\n",
       "12    KNeighborsClassifier      wordnet_lemma_tokenizer  0.995699  0.995698"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.5.4 ###\n",
    "\n",
    "result_df = pd.DataFrame(results3)\n",
    "\n",
    "result_df[['model','tokenizer','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy','f1_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.5.4 การจำแนกข้อความเนื้อความของบทความ (contents) ที่ทำการ preprocess โดยใช้ snowball_stem_tokenizer แล้วทำการลดมิติข้อมูล ด้วย KNeighborsClassifier ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 99.7849% และ f1 score อยู่ที่ 0.997850\n",
    "\n",
    "ซึ่งสรุปได้ว่าการลดมิติข้อมูลด้วย LDA ทำให้การจำแนกมีประสิทธิภาพดีขึ้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c00f123790>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score_idx= result_df[['model','tokenizer','accuracy','f1_score']] .sort_values(by=['accuracy'], ascending=False).head(1).index[0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm[best_score_idx],\n",
    "                                display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Try Transforming with LDA 2\n",
    "\n",
    "นำข้อมูลหัวข้อต่อกับเนื้อความของบทความ (contents_with_title_X) มาทดลองลดมิติข้อมูลลงด้วย LDA และทำการจำแนกแบบเดียวกันกับข้อที่ 3.4 เพื่อดูว่าจะทำให้การจำแนกมีประสิทธิภาพดีขึ้นหรือไม่"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.1 ลดมิติข้อมูลหัวข้อต่อกับเนื้อความของบทความ (contents_with_title_X) ด้วย LDA ให้เหลือ 2 features ตามเซลล์โค้ดที่ 3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data tokenized by word_tokenizer\n",
      "Transforming data tokenized by porter_stem_tokenizer\n",
      "Transforming data tokenized by snowball_stem_tokenizer\n",
      "Transforming data tokenized by lancaster_stem_tokenizer\n",
      "Transforming data tokenized by wordnet_lemma_tokenizer\n",
      "Transforming data tokenized by wordnet_lemma_pos_tokenizer\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.6.1 ###\n",
    "\n",
    "contents_with_title_X_lda = dict()\n",
    "\n",
    "for tokenizer_name, X in contents_with_title_X.items():\n",
    "  print(f'Transforming data tokenized by {tokenizer_name}')\n",
    "  lda = LDA(n_components=2)\n",
    "  contents_with_title_X_lda[tokenizer_name] = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.2 กำหนด model และช่วงของค่า parameter ที่ต้องการทำ tuning ตามเซลล์โค้ดที่ 3.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code Cell 3.6.2 ###\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": list(range(3, 16, 2))}\n",
    "    },\n",
    "    {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            \"C\": np.arange(0.1, 1.1, 0.1)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": list(range(25, 201, 25)),\n",
    "            \"min_samples_split\": list(range(5, 26, 5)),\n",
    "            \"random_state\": [28]\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.3 ทำการ parameter tuning หา parameter ที่ให้ค่า accuracy ที่ดีที่สุดด้วย 5-fold cross validation (GridSearchCV) ของคู่ model กับข้อมูลที่ผ่านการเตรียมด้วย tokenizer แบบต่างๆ จากนั้นนำมาทดสอบกับ test set เพื่อประเมินประสิทธิภาพ model ตามเซลล์โค้ดที่ 3.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs tokenized by word_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9989, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by porter_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 1.0000, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by snowball_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 1.0000, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by lancaster_stem_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 0.9989, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9979, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n",
      "Docs tokenized by wordnet_lemma_pos_tokenizer\n",
      "- Tuning KNeighborsClassifier:\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best tuning: acc 0.9989, params {'n_neighbors': 3}\n",
      "- Tuning LogisticRegression:\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best tuning: acc 1.0000, params {'C': 0.1, 'solver': 'newton-cg'}\n",
      "- Tuning RandomForestClassifier:\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best tuning: acc 0.9989, params {'min_samples_split': 5, 'n_estimators': 25, 'random_state': 28}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Code Cell 3.6.3 ###\n",
    "\n",
    "results4 = {\n",
    "    \"model\": [],\n",
    "    \"tokenizer\": [],\n",
    "    \"best_tuning_params\": [],\n",
    "    \"best_tuning_acc\": [],\n",
    "    \"accuracy\":[],\n",
    "    \"f1_score\":[],\n",
    "}\n",
    "cm = []\n",
    "y = targets\n",
    "\n",
    "for tokenizer_name, X in contents_with_title_X_lda.items():\n",
    "    print(f'Docs tokenized by {tokenizer_name}')\n",
    "\n",
    "    # Stratified train-test split with test size of 33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "        random_state=50, test_size=.33, stratify=y) \n",
    "\n",
    "    for model in models:\n",
    "        print(f\"- Tuning {type(model['model']).__name__}:\")\n",
    "\n",
    "        # Search for best set of parameters, using 5-fold cross validation\n",
    "        clf = GridSearchCV(model['model'], model['params'], cv=5, n_jobs=-1, verbose=1)\n",
    "        result = clf.fit(X_train, y_train)\n",
    "        results4['model'].append(type(model['model']).__name__)\n",
    "        results4['tokenizer'].append(tokenizer_name)\n",
    "        results4['best_tuning_params'].append(result.best_params_)\n",
    "        results4['best_tuning_acc'].append(result.best_score_)\n",
    "        print(f'Best tuning: acc {result.best_score_:.4f}, params {result.best_params_}')\n",
    "\n",
    "        # Test model with best set of parameters from GridSearchCV\n",
    "        model = model['model']\n",
    "        model.set_params(**result.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm.append(confusion_matrix(y_test, y_pred, labels=clf.classes_))\n",
    "        results4['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results4['f1_score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.4 แสดงผลลัพธ์จากข้อ 3.6.3 ตามเซลล์โค้ดที่ 3.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.997848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.995699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>porter_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>snowball_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lancaster_stem_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wordnet_lemma_pos_tokenizer</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                    tokenizer  accuracy  f1_score\n",
       "12    KNeighborsClassifier      wordnet_lemma_tokenizer  0.997849  0.997848\n",
       "15    KNeighborsClassifier  wordnet_lemma_pos_tokenizer  0.995699  0.995699\n",
       "2   RandomForestClassifier               word_tokenizer  0.995699  0.995699\n",
       "14  RandomForestClassifier      wordnet_lemma_tokenizer  0.995699  0.995699\n",
       "0     KNeighborsClassifier               word_tokenizer  0.993548  0.993553\n",
       "1       LogisticRegression               word_tokenizer  0.993548  0.993553\n",
       "3     KNeighborsClassifier        porter_stem_tokenizer  0.993548  0.993553\n",
       "4       LogisticRegression        porter_stem_tokenizer  0.993548  0.993553\n",
       "5   RandomForestClassifier        porter_stem_tokenizer  0.993548  0.993553\n",
       "6     KNeighborsClassifier      snowball_stem_tokenizer  0.993548  0.993553\n",
       "7       LogisticRegression      snowball_stem_tokenizer  0.993548  0.993553\n",
       "8   RandomForestClassifier      snowball_stem_tokenizer  0.993548  0.993553\n",
       "9     KNeighborsClassifier     lancaster_stem_tokenizer  0.993548  0.993553\n",
       "10      LogisticRegression     lancaster_stem_tokenizer  0.993548  0.993553\n",
       "11  RandomForestClassifier     lancaster_stem_tokenizer  0.993548  0.993553\n",
       "13      LogisticRegression      wordnet_lemma_tokenizer  0.993548  0.993553\n",
       "16      LogisticRegression  wordnet_lemma_pos_tokenizer  0.993548  0.993553\n",
       "17  RandomForestClassifier  wordnet_lemma_pos_tokenizer  0.993548  0.993553"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code Cell 3.6.4 ###\n",
    "\n",
    "result_df = pd.DataFrame(results4)\n",
    "\n",
    "result_df[['model','tokenizer','accuracy','f1_score']] \\\n",
    "    .sort_values(by=['accuracy','f1_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ของเซลล์โค้ดที่ 3.6.4 การจำแนกข้อมูลหัวข้อต่อกับเนื้อความของบทความ (contents_with_title_X) ที่ทำการ preprocess โดยใช้ wordnet_lemma_tokenizer แล้วทำการลดมิติข้อมูล ด้วย KNeighborsClassifier ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 99.7849% และ f1 score อยู่ที่ 0.997848\n",
    "\n",
    "ซึ่งสรุปได้ว่าการลดมิติข้อมูลด้วย LDA ทำให้การจำแนกมีประสิทธิภาพดีขึ้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c00f77e400>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score_idx= result_df[['model','tokenizer','accuracy','f1_score']] .sort_values(by=['accuracy'], ascending=False).head(1).index[0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm[best_score_idx],\n",
    "                                display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลการทดลองทั้งหมด 4 การทดลองได้แก่\n",
    "- `การทดลองที่ 1 `: ใช้เนื้อความของบทความ\n",
    "- `การทดลองที่ 2 `: ใช้หัวข้อต่อกับเนื้อความของบทความ\n",
    "- `การทดลองที่ 3 `: ใช้เนื้อความของบทความ มาทดลองลดมิติข้อมูลลงด้วย LDA ให้เหลือ 2 มิติ\n",
    "- `การทดลองที่ 4 `: ใช้หัวข้อต่อกับเนื้อความของบทความ มาทดลองลดมิติข้อมูลลงด้วย LDA ให้เหลือ 2 มิติ\n",
    "\n",
    "\n",
    "ในแต่ละการทดลอง ประกอบไปด้วย 3 models ที่ผ่านการ parameter tuning ได้แก่\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression \n",
    "\n",
    "และ 6 tokenizers ได้แก่ \n",
    "- word_tokenizer\n",
    "- lancaster_stem_tokenizer\n",
    "- snowball_stem_tokenizer\n",
    "- porter_stem_tokenizer\n",
    "- wordnet_lemma_tokenizer\n",
    "- wordnet_lemma_pos_tokenizer\n",
    "\n",
    "จากการทดลองพบว่า\n",
    "\n",
    "- `การทดลองที่ 1 `: ใช้ `lancaster_stem_tokenizer` ด้วย `RandomForestClassifier` ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 98.0645% และ f1 score อยู่ที่ 0.980610\n",
    "- `การทดลองที่ 2 `: ใช้ `snowball_stem_tokenizer` ด้วย `RandomForestClassifier` ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 97.6344% และ f1 score อยู่ที่ 0.976341\n",
    "- `การทดลองที่ 3 `: ใช้ `snowball_stem_tokenizer` ด้วย `KNeighborsClassifier` ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 99.7849% และ f1 score อยู่ที่ 0.997850\n",
    "- `การทดลองที่ 4 `: ใช้ `wordnet_lemma_tokenizer` ด้วย `KNeighborsClassifier` ให้ประสิทธิภาพดีที่สุด ซึ่งมี accuracy อยู่ที่ 99.7849% และ f1 score อยู่ที่ 0.997848\n",
    "\n",
    "เห็นได้ว่า `การทดลองที่ 3 และ 4` ที่ได้มีการลดมิติข้อมูลลงด้วย LDA มีประสิทธิภาพเพิ่มขึ้น รวมไปถึงโมเดล `KNeighborsClassifier` มีประสิทธิภาพเพิ่มขึ้นอย่างเห็นได้ชัด เมื่อเทียบกับการทดลองที่ยังไม่ได้ลดมิติของข้อมูลจะพบว่า `KNeighborsClassifier` จะมีประสิทธิภาพอยู่ในอันดับหลังๆ\n",
    "\n",
    "`สรุปคือ` การเลือกใช้เนื้อความเพียงอย่างเดียวจากนั้นทำการลดมิติข้อมูลด้วย LDA แล้วทำ \n",
    "tokenize ด้วย `snowball_stem_tokenize` และเลือกใช้โมเดล `KNeighborsClassifier` ให้ประสิทธิภาพดีที่สุด"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
